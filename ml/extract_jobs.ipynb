{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d46663d4",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-22T07:13:04.456156Z",
     "iopub.status.busy": "2025-05-22T07:13:04.455827Z",
     "iopub.status.idle": "2025-05-22T07:13:06.068729Z",
     "shell.execute_reply": "2025-05-22T07:13:06.068197Z"
    },
    "papermill": {
     "duration": 1.625289,
     "end_time": "2025-05-22T07:13:06.070063",
     "exception": false,
     "start_time": "2025-05-22T07:13:04.444774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a57f6ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T07:13:06.083778Z",
     "iopub.status.busy": "2025-05-22T07:13:06.083084Z",
     "iopub.status.idle": "2025-05-22T07:13:06.458089Z",
     "shell.execute_reply": "2025-05-22T07:13:06.457525Z"
    },
    "papermill": {
     "duration": 0.382881,
     "end_time": "2025-05-22T07:13:06.459459",
     "exception": false,
     "start_time": "2025-05-22T07:13:06.076578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library berhasil diimpor.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"Library berhasil diimpor.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9299033",
   "metadata": {
    "papermill": {
     "duration": 0.005437,
     "end_time": "2025-05-22T07:13:06.470741",
     "exception": false,
     "start_time": "2025-05-22T07:13:06.465304",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Analysis Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99dae007",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T07:13:06.482886Z",
     "iopub.status.busy": "2025-05-22T07:13:06.482593Z",
     "iopub.status.idle": "2025-05-22T07:13:06.485828Z",
     "shell.execute_reply": "2025-05-22T07:13:06.485311Z"
    },
    "papermill": {
     "duration": 0.010316,
     "end_time": "2025-05-22T07:13:06.486762",
     "exception": false,
     "start_time": "2025-05-22T07:13:06.476446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "url_da = \"https://www.linkedin.com/jobs/search/?currentJobId=3168594862&geoId=102478259&keywords=data%20analysis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4268cc2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T07:13:06.499632Z",
     "iopub.status.busy": "2025-05-22T07:13:06.499422Z",
     "iopub.status.idle": "2025-05-22T07:19:49.277009Z",
     "shell.execute_reply": "2025-05-22T07:19:49.276415Z"
    },
    "papermill": {
     "duration": 402.785929,
     "end_time": "2025-05-22T07:19:49.278590",
     "exception": false,
     "start_time": "2025-05-22T07:13:06.492661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "locations = []\n",
    "titles = []\n",
    "countries = []    \n",
    "links = []\n",
    "company_name = []\n",
    "job_description = []\n",
    "job_requirement = []\n",
    "work_types = []\n",
    "\n",
    "# Loop untuk scraping daftar pekerjaan\n",
    "for i in range(0, 100, 25):\n",
    "    url = url_da + \"&start=\" + str(i)\n",
    "    request = requests.get(url)\n",
    "    soup = BeautifulSoup(request.text, 'html.parser')\n",
    "\n",
    "    # Location\n",
    "    location = soup.findAll(\"span\", {\"class\": \"job-search-card__location\"})\n",
    "    for loc in location:\n",
    "        locations.append(loc.text.replace(\"\\n\", \" \").strip())\n",
    "\n",
    "    # Title\n",
    "    title = soup.findAll(\"h3\", {\"class\": \"base-search-card__title\"})\n",
    "    for t in title:\n",
    "        titles.append(t.text.replace(\"\\n\", \" \").strip())\n",
    "\n",
    "    # Country\n",
    "    for c in location:\n",
    "        countries.append(c.text.replace(\"\\n\", \" \").strip().split(',')[-1])\n",
    "\n",
    "    # Job links\n",
    "    job_links = soup.findAll(\"a\", {\"class\": \"base-card__full-link\"})\n",
    "    for link in job_links:\n",
    "        links.append(link[\"href\"])\n",
    "\n",
    "    # Company names\n",
    "    names = soup.findAll(\"a\", {\"class\": \"hidden-nested-link\"})\n",
    "    for name in names:\n",
    "        company_name.append(name.text.replace(\"\\n\", \" \").strip())\n",
    "\n",
    "# Keywords untuk membagi deskripsi dan requirements\n",
    "desc_keywords = ['responsibilities', 'responsibilities:', 'what you’ll do', 'what you will do', 'deskripsi', 'tugas', 'role', 'job description:', 'job description', \n",
    "                 'your main duties in flying with us', 'your impact', \"you’ll get to\"]\n",
    "req_keywords = ['requirement', 'requirement:', 'requirements', 'requirements:', 'qualification', 'qualification:', 'qualifications', 'qualifications:', 'kualifikasi',\n",
    "                'what you’ll need', 'what you will need', 'you should have', 'skills', 'experience', 'job requirements', 'mandatory belongings that you must prepare', \n",
    "                'who we look for', \"you’ll need to succeed\", 'what this role needs', 'kriteria']\n",
    "\n",
    "# Loop untuk scraping detail tiap job\n",
    "for link in links:\n",
    "    try:\n",
    "        job_page = requests.get(link)\n",
    "        job_soup = BeautifulSoup(job_page.text, 'html.parser')\n",
    "\n",
    "        # --- Ekstraksi Work Type (Fix sesuai struktur HTML) ---\n",
    "        work_type_found = \"Not Found\"\n",
    "        button = job_soup.find(\"button\", class_=\"job-details-preferences-and-skills\")\n",
    "        if button:\n",
    "            span_aria = button.find_all(\"span\", attrs={\"aria-hidden\": \"true\"})\n",
    "            for span in span_aria:\n",
    "                text = span.get_text(strip=True)\n",
    "                for tipe in [\"Remote\", \"Hybrid\", \"On-site\"]:\n",
    "                    if tipe.lower() in text.lower():\n",
    "                        work_type_found = tipe\n",
    "                        break\n",
    "        work_types.append(work_type_found)\n",
    "\n",
    "        # --- Ekstraksi Job Description & Requirements ---\n",
    "        desc_block = job_soup.find(\"div\", {\"class\": \"show-more-less-html__markup\"})\n",
    "        if desc_block:\n",
    "            items = desc_block.find_all(\"li\")\n",
    "            li_texts = [li.text.strip() for li in items]\n",
    "\n",
    "            desc_part = []\n",
    "            req_part = []\n",
    "\n",
    "            for li_text in li_texts:\n",
    "                text_lower = li_text.lower()\n",
    "                if any(k in text_lower for k in req_keywords):\n",
    "                    req_part.append(li_text)\n",
    "                elif any(k in text_lower for k in desc_keywords):\n",
    "                    desc_part.append(li_text)\n",
    "                else:\n",
    "                    if any(word in text_lower for word in ['analyze', 'develop', 'manage', 'design', 'plan']):\n",
    "                        desc_part.append(li_text)\n",
    "                    else:\n",
    "                        req_part.append(li_text)\n",
    "\n",
    "            job_description.append(\" | \".join(desc_part) if desc_part else \"Not Found\")\n",
    "            job_requirement.append(\" | \".join(req_part) if req_part else \"Not Found\")\n",
    "        else:\n",
    "            job_description.append(\"Not Found\")\n",
    "            job_requirement.append(\"Not Found\")\n",
    "\n",
    "        time.sleep(1)\n",
    "    except Exception as e:\n",
    "        job_description.append(\"Error: \" + str(e))\n",
    "        job_requirement.append(\"Error: \" + str(e))\n",
    "        work_types.append(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25769d27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T07:19:49.291386Z",
     "iopub.status.busy": "2025-05-22T07:19:49.291133Z",
     "iopub.status.idle": "2025-05-22T07:19:49.324354Z",
     "shell.execute_reply": "2025-05-22T07:19:49.323615Z"
    },
    "papermill": {
     "duration": 0.040608,
     "end_time": "2025-05-22T07:19:49.325495",
     "exception": false,
     "start_time": "2025-05-22T07:19:49.284887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Country</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Job Requirements</th>\n",
       "      <th>Work Type</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst, Business Intelligence</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Assist the various business units as a discuss...</td>\n",
       "      <td>Serve as in-consultant who simplifies complex ...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/data-analyst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Business Analyst - SPX Express (Jakarta)</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Perform deep data analysis to find pattern of ...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/business-ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst Marketing</td>\n",
       "      <td>PT ASTRA OTOPARTS Tbk</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Analysis about domestic performance, survey, r...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/data-analyst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>OTO</td>\n",
       "      <td>Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Collecting, analyzing and interpreting data, a...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/business-ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wholesale Risk Analyst</td>\n",
       "      <td>PT. Bank Tabungan Negara (Persero) Tbk</td>\n",
       "      <td>Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/wholesale-ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Junior Data Analyst</td>\n",
       "      <td>PT Smart Multi Finance</td>\n",
       "      <td>Serpong, Banten, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Minimal S1 di bidang terkait, seperti: Statist...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/junior-data-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Customer Care Agent</td>\n",
       "      <td>Wings Group Indonesia (Sayap Mas Utama)</td>\n",
       "      <td>East Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Melakukan survey pelayanan dan mengusulkan act...</td>\n",
       "      <td>Melayani pertanyaan dan keluhan customers terh...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/customer-car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Management Trainee</td>\n",
       "      <td>PT Astra International Tbk</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Gelar sarjana dari jurusan apa pun | Lulusan b...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/management-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>Performance Specialist</td>\n",
       "      <td>PT Alam Sutera Realty Tbk.</td>\n",
       "      <td>Tangerang, Banten, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Bachelor's Degree majoring in Communication Sc...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/performance-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>Finance Analyst</td>\n",
       "      <td>McKinsey &amp; Company</td>\n",
       "      <td>Jakarta Metropolitan Area</td>\n",
       "      <td>Jakarta Metropolitan Area</td>\n",
       "      <td>Strong stakeholder management and the ability ...</td>\n",
       "      <td>Continuous learning Our learning and apprentic...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/finance-anal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Title  \\\n",
       "0         Data Analyst, Business Intelligence   \n",
       "1    Business Analyst - SPX Express (Jakarta)   \n",
       "2                      Data Analyst Marketing   \n",
       "3                            Business Analyst   \n",
       "4                      Wholesale Risk Analyst   \n",
       "..                                        ...   \n",
       "235                       Junior Data Analyst   \n",
       "236                       Customer Care Agent   \n",
       "237                        Management Trainee   \n",
       "238                    Performance Specialist   \n",
       "239                           Finance Analyst   \n",
       "\n",
       "                                     Company  \\\n",
       "0                                     Shopee   \n",
       "1                                     Shopee   \n",
       "2                      PT ASTRA OTOPARTS Tbk   \n",
       "3                                        OTO   \n",
       "4     PT. Bank Tabungan Negara (Persero) Tbk   \n",
       "..                                       ...   \n",
       "235                   PT Smart Multi Finance   \n",
       "236  Wings Group Indonesia (Sayap Mas Utama)   \n",
       "237               PT Astra International Tbk   \n",
       "238               PT Alam Sutera Realty Tbk.   \n",
       "239                       McKinsey & Company   \n",
       "\n",
       "                             Location                    Country  \\\n",
       "0                  Jakarta, Indonesia                  Indonesia   \n",
       "1                  Jakarta, Indonesia                  Indonesia   \n",
       "2         Jakarta, Jakarta, Indonesia                  Indonesia   \n",
       "3                  Jakarta, Indonesia                  Indonesia   \n",
       "4                  Jakarta, Indonesia                  Indonesia   \n",
       "..                                ...                        ...   \n",
       "235        Serpong, Banten, Indonesia                  Indonesia   \n",
       "236  East Jakarta, Jakarta, Indonesia                  Indonesia   \n",
       "237       Jakarta, Jakarta, Indonesia                  Indonesia   \n",
       "238      Tangerang, Banten, Indonesia                  Indonesia   \n",
       "239         Jakarta Metropolitan Area  Jakarta Metropolitan Area   \n",
       "\n",
       "                                       Job Description  \\\n",
       "0    Assist the various business units as a discuss...   \n",
       "1                                            Not Found   \n",
       "2                                            Not Found   \n",
       "3                                            Not Found   \n",
       "4                                            Not Found   \n",
       "..                                                 ...   \n",
       "235                                          Not Found   \n",
       "236  Melakukan survey pelayanan dan mengusulkan act...   \n",
       "237                                          Not Found   \n",
       "238                                          Not Found   \n",
       "239  Strong stakeholder management and the ability ...   \n",
       "\n",
       "                                      Job Requirements  Work Type  \\\n",
       "0    Serve as in-consultant who simplifies complex ...  Not Found   \n",
       "1    Perform deep data analysis to find pattern of ...  Not Found   \n",
       "2    Analysis about domestic performance, survey, r...  Not Found   \n",
       "3    Collecting, analyzing and interpreting data, a...  Not Found   \n",
       "4                                            Not Found  Not Found   \n",
       "..                                                 ...        ...   \n",
       "235  Minimal S1 di bidang terkait, seperti: Statist...  Not Found   \n",
       "236  Melayani pertanyaan dan keluhan customers terh...  Not Found   \n",
       "237  Gelar sarjana dari jurusan apa pun | Lulusan b...  Not Found   \n",
       "238  Bachelor's Degree majoring in Communication Sc...  Not Found   \n",
       "239  Continuous learning Our learning and apprentic...  Not Found   \n",
       "\n",
       "                                                  Link  \n",
       "0    https://id.linkedin.com/jobs/view/data-analyst...  \n",
       "1    https://id.linkedin.com/jobs/view/business-ana...  \n",
       "2    https://id.linkedin.com/jobs/view/data-analyst...  \n",
       "3    https://id.linkedin.com/jobs/view/business-ana...  \n",
       "4    https://id.linkedin.com/jobs/view/wholesale-ri...  \n",
       "..                                                 ...  \n",
       "235  https://id.linkedin.com/jobs/view/junior-data-...  \n",
       "236  https://id.linkedin.com/jobs/view/customer-car...  \n",
       "237  https://id.linkedin.com/jobs/view/management-t...  \n",
       "238  https://id.linkedin.com/jobs/view/performance-...  \n",
       "239  https://id.linkedin.com/jobs/view/finance-anal...  \n",
       "\n",
       "[240 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame({\n",
    "    \"Title\": titles,\n",
    "    \"Company\": company_name,\n",
    "    \"Location\": locations,\n",
    "    \"Country\": countries,\n",
    "    \"Job Description\": job_description,\n",
    "    \"Job Requirements\": job_requirement,\n",
    "    \"Work Type\" : work_types,\n",
    "    \"Link\": links\n",
    "})\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450fc560",
   "metadata": {
    "papermill": {
     "duration": 0.005978,
     "end_time": "2025-05-22T07:19:49.337581",
     "exception": false,
     "start_time": "2025-05-22T07:19:49.331603",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Machine learning jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9552a581",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T07:19:49.350155Z",
     "iopub.status.busy": "2025-05-22T07:19:49.349954Z",
     "iopub.status.idle": "2025-05-22T07:19:49.353253Z",
     "shell.execute_reply": "2025-05-22T07:19:49.352590Z"
    },
    "papermill": {
     "duration": 0.010901,
     "end_time": "2025-05-22T07:19:49.354237",
     "exception": false,
     "start_time": "2025-05-22T07:19:49.343336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "url_ml = \"https://www.linkedin.com/jobs/search/?currentJobId=3168594862&geoId=102478259&keywords=machine%20learning&refresh=true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73fb1075",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T07:19:49.366780Z",
     "iopub.status.busy": "2025-05-22T07:19:49.366574Z",
     "iopub.status.idle": "2025-05-22T07:26:24.799340Z",
     "shell.execute_reply": "2025-05-22T07:26:24.798666Z"
    },
    "papermill": {
     "duration": 395.440684,
     "end_time": "2025-05-22T07:26:24.800739",
     "exception": false,
     "start_time": "2025-05-22T07:19:49.360055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "locations = []\n",
    "titles = []\n",
    "countries = []    \n",
    "links = []\n",
    "company_name = []\n",
    "job_description = []\n",
    "job_requirement = []\n",
    "work_types = []\n",
    "\n",
    "for i in range(0, 100, 25):\n",
    "    url = url_ml + \"&start=\" + str(i)\n",
    "    request = requests.get(url)\n",
    "    soup = BeautifulSoup(request.text, 'html.parser')\n",
    "\n",
    "    # Location\n",
    "    location = soup.findAll(\"span\", {\"class\": \"job-search-card__location\"})\n",
    "    for loc in location:\n",
    "        locations.append(loc.text.replace(\"\\n\", \" \").strip())\n",
    "\n",
    "    # Title\n",
    "    title = soup.findAll(\"h3\", {\"class\": \"base-search-card__title\"})\n",
    "    for t in title:\n",
    "        titles.append(t.text.replace(\"\\n\", \" \").strip())\n",
    "\n",
    "    # Country\n",
    "    for c in location:\n",
    "        countries.append(c.text.replace(\"\\n\", \" \").strip().split(',')[-1])\n",
    "\n",
    "    # Job links\n",
    "    job_links = soup.findAll(\"a\", {\"class\": \"base-card__full-link\"})\n",
    "    for link in job_links:\n",
    "        links.append(link[\"href\"])\n",
    "\n",
    "    # Company names\n",
    "    names = soup.findAll(\"a\", {\"class\": \"hidden-nested-link\"})\n",
    "    for name in names:\n",
    "        company_name.append(name.text.replace(\"\\n\", \" \").strip())\n",
    "\n",
    "# Keywords\n",
    "desc_keywords = ['responsibilities', 'responsibilities:', 'what you’ll do', 'what you will do', 'deskripsi', 'tugas', 'role', 'job description:', 'job description', \n",
    "                 'your main duties in flying with us', 'your impact', \"you’ll get to\"]\n",
    "req_keywords = ['requirement', 'requirement:', 'requirements', 'requirements:', 'qualification', 'qualification:', 'qualifications', 'qualifications:', 'kualifikasi',\n",
    "                'what you’ll need', 'what you will need', 'you should have', 'skills', 'experience', 'job requirements', 'mandatory belongings that you must prepare', \n",
    "                'who we look for', \"you’ll need to succeed\", 'what this role needs', 'kriteria']\n",
    "\n",
    "for link in links:\n",
    "    try:\n",
    "        job_page = requests.get(link)\n",
    "        job_soup = BeautifulSoup(job_page.text, 'html.parser')\n",
    "\n",
    "        # Extract work type\n",
    "        work_type_found = \"Not Found\"\n",
    "        preference_button = job_soup.find(\"button\", class_=\"job-details-preferences-and-skills\")\n",
    "        if preference_button:\n",
    "            pill_divs = preference_button.find_all(\"div\", class_=\"job-details-preferences-and-skills__pill\")\n",
    "            for pill in pill_divs:\n",
    "                span = pill.find(\"span\", class_=\"ui-label ui-label--accent-3 text-body-small\")\n",
    "                if span and span.text.strip() in [\"Remote\", \"On-site\", \"Hybrid\"]:\n",
    "                    work_type_found = span.text.strip()\n",
    "                    break\n",
    "        work_types.append(work_type_found)\n",
    "\n",
    "        # Extract job description & requirements\n",
    "        desc_block = job_soup.find(\"div\", {\"class\": \"show-more-less-html__markup\"})\n",
    "        if desc_block:\n",
    "            items = desc_block.find_all(\"li\")\n",
    "            li_texts = [li.text.strip() for li in items]\n",
    "\n",
    "            desc_part = []\n",
    "            req_part = []\n",
    "\n",
    "            for li_text in li_texts:\n",
    "                text_lower = li_text.lower()\n",
    "                \n",
    "                if any(k in text_lower for k in req_keywords):\n",
    "                    req_part.append(li_text)\n",
    "                elif any(k in text_lower for k in desc_keywords):\n",
    "                    desc_part.append(li_text)\n",
    "                else:\n",
    "                    if any(word in text_lower for word in ['analyze', 'develop', 'manage', 'design', 'plan']):\n",
    "                        desc_part.append(li_text)\n",
    "                    else:\n",
    "                        req_part.append(li_text)\n",
    "\n",
    "            job_description.append(\" | \".join(desc_part) if desc_part else \"Not Found\")\n",
    "            job_requirement.append(\" | \".join(req_part) if req_part else \"Not Found\")\n",
    "        else:\n",
    "            job_description.append(\"Not Found\")\n",
    "            job_requirement.append(\"Not Found\")\n",
    "\n",
    "        time.sleep(1)\n",
    "    except Exception as e:\n",
    "        job_description.append(\"Error: \" + str(e))\n",
    "        job_requirement.append(\"Error: \" + str(e))\n",
    "        work_types.append(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b892fba8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T07:26:24.815549Z",
     "iopub.status.busy": "2025-05-22T07:26:24.815341Z",
     "iopub.status.idle": "2025-05-22T07:26:24.828098Z",
     "shell.execute_reply": "2025-05-22T07:26:24.827362Z"
    },
    "papermill": {
     "duration": 0.021257,
     "end_time": "2025-05-22T07:26:24.829255",
     "exception": false,
     "start_time": "2025-05-22T07:26:24.807998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Country</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Job Requirements</th>\n",
       "      <th>Work Type</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>INDICO by Telkomsel</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Design and implement machine learning models a...</td>\n",
       "      <td>Conduct experiments to optimize model performa...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/machine-lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist, Business Intelligence</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Prototyping, developing, and deploying advance...</td>\n",
       "      <td>Communicating with the product and business te...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst, Business Intelligence</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Assist the various business units as a discuss...</td>\n",
       "      <td>Serve as in-consultant who simplifies complex ...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/data-analyst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AI/Machine Learning (Software Developer) (ASAP)</td>\n",
       "      <td>SIGMATECH</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Menguasai backend development dengan Flutter, ...</td>\n",
       "      <td>Menguasai bahasa pemrograman Python untuk trai...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/ai-machine-l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>tiket.com</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Involve in model development using machine lea...</td>\n",
       "      <td>Conduct exploratory data analysis and grab ins...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/data-science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Machine Learning Manager (Indonesia)</td>\n",
       "      <td>BJAK</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Design, develop, and implement AI models, algo...</td>\n",
       "      <td>Lead and mentor a team of AI engineers, provid...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/machine-lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kredivo Group</td>\n",
       "      <td>Jakarta Metropolitan Area</td>\n",
       "      <td>Jakarta Metropolitan Area</td>\n",
       "      <td>Researching &amp; Development on how to improve ou...</td>\n",
       "      <td>Working in a multi-disciplined team where you’...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Analytical Junior Research Assistant Microbiology</td>\n",
       "      <td>Dexa Group</td>\n",
       "      <td>North Cikarang, West Java, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Melakukan pengujian sampel stabilita dan memba...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/analytical-j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>AI/ML Senior Software Engineer (Indonesia)</td>\n",
       "      <td>BJAK</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Design, develop, and implement AI models, algo...</td>\n",
       "      <td>Work with product managers and stakeholders to...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/ai-ml-senior...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Catalyst</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Design, build, and drive adoption of data dash...</td>\n",
       "      <td>Build data dashboards to monitor company perfo...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/data-analyst...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title              Company  \\\n",
       "0                            Machine Learning Engineer  INDICO by Telkomsel   \n",
       "1                Data Scientist, Business Intelligence               Shopee   \n",
       "2                  Data Analyst, Business Intelligence               Shopee   \n",
       "3      AI/Machine Learning (Software Developer) (ASAP)            SIGMATECH   \n",
       "4                                  Data Science Intern            tiket.com   \n",
       "..                                                 ...                  ...   \n",
       "235               Machine Learning Manager (Indonesia)                 BJAK   \n",
       "236                                     Data Scientist        Kredivo Group   \n",
       "237  Analytical Junior Research Assistant Microbiology           Dexa Group   \n",
       "238         AI/ML Senior Software Engineer (Indonesia)                 BJAK   \n",
       "239                                       Data Analyst             Catalyst   \n",
       "\n",
       "                                 Location                    Country  \\\n",
       "0             Jakarta, Jakarta, Indonesia                  Indonesia   \n",
       "1                      Jakarta, Indonesia                  Indonesia   \n",
       "2                      Jakarta, Indonesia                  Indonesia   \n",
       "3             Jakarta, Jakarta, Indonesia                  Indonesia   \n",
       "4             Jakarta, Jakarta, Indonesia                  Indonesia   \n",
       "..                                    ...                        ...   \n",
       "235                             Indonesia                  Indonesia   \n",
       "236             Jakarta Metropolitan Area  Jakarta Metropolitan Area   \n",
       "237  North Cikarang, West Java, Indonesia                  Indonesia   \n",
       "238                             Indonesia                  Indonesia   \n",
       "239           Jakarta, Jakarta, Indonesia                  Indonesia   \n",
       "\n",
       "                                       Job Description  \\\n",
       "0    Design and implement machine learning models a...   \n",
       "1    Prototyping, developing, and deploying advance...   \n",
       "2    Assist the various business units as a discuss...   \n",
       "3    Menguasai backend development dengan Flutter, ...   \n",
       "4    Involve in model development using machine lea...   \n",
       "..                                                 ...   \n",
       "235  Design, develop, and implement AI models, algo...   \n",
       "236  Researching & Development on how to improve ou...   \n",
       "237                                          Not Found   \n",
       "238  Design, develop, and implement AI models, algo...   \n",
       "239  Design, build, and drive adoption of data dash...   \n",
       "\n",
       "                                      Job Requirements  Work Type  \\\n",
       "0    Conduct experiments to optimize model performa...  Not Found   \n",
       "1    Communicating with the product and business te...  Not Found   \n",
       "2    Serve as in-consultant who simplifies complex ...  Not Found   \n",
       "3    Menguasai bahasa pemrograman Python untuk trai...  Not Found   \n",
       "4    Conduct exploratory data analysis and grab ins...  Not Found   \n",
       "..                                                 ...        ...   \n",
       "235  Lead and mentor a team of AI engineers, provid...  Not Found   \n",
       "236  Working in a multi-disciplined team where you’...  Not Found   \n",
       "237  Melakukan pengujian sampel stabilita dan memba...  Not Found   \n",
       "238  Work with product managers and stakeholders to...  Not Found   \n",
       "239  Build data dashboards to monitor company perfo...  Not Found   \n",
       "\n",
       "                                                  Link  \n",
       "0    https://id.linkedin.com/jobs/view/machine-lear...  \n",
       "1    https://id.linkedin.com/jobs/view/data-scienti...  \n",
       "2    https://id.linkedin.com/jobs/view/data-analyst...  \n",
       "3    https://id.linkedin.com/jobs/view/ai-machine-l...  \n",
       "4    https://id.linkedin.com/jobs/view/data-science...  \n",
       "..                                                 ...  \n",
       "235  https://id.linkedin.com/jobs/view/machine-lear...  \n",
       "236  https://id.linkedin.com/jobs/view/data-scienti...  \n",
       "237  https://id.linkedin.com/jobs/view/analytical-j...  \n",
       "238  https://id.linkedin.com/jobs/view/ai-ml-senior...  \n",
       "239  https://id.linkedin.com/jobs/view/data-analyst...  \n",
       "\n",
       "[240 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame({\n",
    "    \"Title\": titles,\n",
    "    \"Company\": company_name,\n",
    "    \"Location\": locations,\n",
    "    \"Country\": countries,\n",
    "    \"Job Description\": job_description,\n",
    "    \"Job Requirements\": job_requirement,\n",
    "    \"Work Type\" : work_types,\n",
    "    \"Link\": links\n",
    "})\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc702ee",
   "metadata": {
    "papermill": {
     "duration": 0.006392,
     "end_time": "2025-05-22T07:26:24.842530",
     "exception": false,
     "start_time": "2025-05-22T07:26:24.836138",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Software testing jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3fa0847",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T07:26:24.856202Z",
     "iopub.status.busy": "2025-05-22T07:26:24.855977Z",
     "iopub.status.idle": "2025-05-22T07:26:24.859427Z",
     "shell.execute_reply": "2025-05-22T07:26:24.858723Z"
    },
    "papermill": {
     "duration": 0.0115,
     "end_time": "2025-05-22T07:26:24.860531",
     "exception": false,
     "start_time": "2025-05-22T07:26:24.849031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "url_testing = \"https://www.linkedin.com/jobs/search/?currentJobId=3251187123&geoId=102478259&keywords=software%20tester&refresh=true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "346bc95c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T07:26:24.874342Z",
     "iopub.status.busy": "2025-05-22T07:26:24.874107Z",
     "iopub.status.idle": "2025-05-22T07:33:24.269390Z",
     "shell.execute_reply": "2025-05-22T07:33:24.268719Z"
    },
    "papermill": {
     "duration": 419.403801,
     "end_time": "2025-05-22T07:33:24.270800",
     "exception": false,
     "start_time": "2025-05-22T07:26:24.866999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "locations = []\n",
    "titles = []\n",
    "countries = []    \n",
    "links = []\n",
    "company_name = []\n",
    "job_description = []\n",
    "job_requirement = []\n",
    "work_types = []\n",
    "\n",
    "for i in range(0, 100, 25):\n",
    "    url = url_testing + \"&start=\" + str(i)\n",
    "    request = requests.get(url)\n",
    "    soup = BeautifulSoup(request.text, 'html.parser')\n",
    "\n",
    "    # Location\n",
    "    location = soup.findAll(\"span\", {\"class\": \"job-search-card__location\"})\n",
    "    for loc in location:\n",
    "        locations.append(loc.text.replace(\"\\n\", \" \").strip())\n",
    "\n",
    "    # Title\n",
    "    title = soup.findAll(\"h3\", {\"class\": \"base-search-card__title\"})\n",
    "    for t in title:\n",
    "        titles.append(t.text.replace(\"\\n\", \" \").strip())\n",
    "\n",
    "    # Country\n",
    "    for c in location:\n",
    "        countries.append(c.text.replace(\"\\n\", \" \").strip().split(',')[-1])\n",
    "\n",
    "    # Job links\n",
    "    job_links = soup.findAll(\"a\", {\"class\": \"base-card__full-link\"})\n",
    "    for link in job_links:\n",
    "        links.append(link[\"href\"])\n",
    "\n",
    "    # Company names\n",
    "    names = soup.findAll(\"a\", {\"class\": \"hidden-nested-link\"})\n",
    "    for name in names:\n",
    "        company_name.append(name.text.replace(\"\\n\", \" \").strip())\n",
    "\n",
    "# Keywords\n",
    "desc_keywords = ['responsibilities', 'responsibilities:', 'what you’ll do', 'what you will do', 'deskripsi', 'tugas', 'role', 'job description:', 'job description', \n",
    "                 'your main duties in flying with us', 'your impact', \"you’ll get to\"]\n",
    "req_keywords = ['requirement', 'requirement:', 'requirements', 'requirements:', 'qualification', 'qualification:', 'qualifications', 'qualifications:', 'kualifikasi',\n",
    "                'what you’ll need', 'what you will need', 'you should have', 'skills', 'experience', 'job requirements', 'mandatory belongings that you must prepare', \n",
    "                'who we look for', \"you’ll need to succeed\", 'what this role needs', 'kriteria']\n",
    "\n",
    "for link in links:\n",
    "    try:\n",
    "        job_page = requests.get(link)\n",
    "        job_soup = BeautifulSoup(job_page.text, 'html.parser')\n",
    "\n",
    "        # Extract work type\n",
    "        work_type_found = \"Not Found\"\n",
    "        preference_button = job_soup.find(\"button\", class_=\"job-details-preferences-and-skills\")\n",
    "        if preference_button:\n",
    "            pill_divs = preference_button.find_all(\"div\", class_=\"job-details-preferences-and-skills__pill\")\n",
    "            for pill in pill_divs:\n",
    "                span = pill.find(\"span\", class_=\"ui-label ui-label--accent-3 text-body-small\")\n",
    "                if span and span.text.strip() in [\"Remote\", \"On-site\", \"Hybrid\"]:\n",
    "                    work_type_found = span.text.strip()\n",
    "                    break\n",
    "        work_types.append(work_type_found)\n",
    "\n",
    "        # Extract job description & requirements\n",
    "        desc_block = job_soup.find(\"div\", {\"class\": \"show-more-less-html__markup\"})\n",
    "        if desc_block:\n",
    "            items = desc_block.find_all(\"li\")\n",
    "            li_texts = [li.text.strip() for li in items]\n",
    "\n",
    "            desc_part = []\n",
    "            req_part = []\n",
    "\n",
    "            for li_text in li_texts:\n",
    "                text_lower = li_text.lower()\n",
    "                \n",
    "                if any(k in text_lower for k in req_keywords):\n",
    "                    req_part.append(li_text)\n",
    "                elif any(k in text_lower for k in desc_keywords):\n",
    "                    desc_part.append(li_text)\n",
    "                else:\n",
    "                    if any(word in text_lower for word in ['analyze', 'develop', 'manage', 'design', 'plan']):\n",
    "                        desc_part.append(li_text)\n",
    "                    else:\n",
    "                        req_part.append(li_text)\n",
    "\n",
    "            job_description.append(\" | \".join(desc_part) if desc_part else \"Not Found\")\n",
    "            job_requirement.append(\" | \".join(req_part) if req_part else \"Not Found\")\n",
    "        else:\n",
    "            job_description.append(\"Not Found\")\n",
    "            job_requirement.append(\"Not Found\")\n",
    "\n",
    "        time.sleep(1)\n",
    "    except Exception as e:\n",
    "        job_description.append(\"Error: \" + str(e))\n",
    "        job_requirement.append(\"Error: \" + str(e))\n",
    "        work_types.append(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b49c6524",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T07:33:24.285097Z",
     "iopub.status.busy": "2025-05-22T07:33:24.284907Z",
     "iopub.status.idle": "2025-05-22T07:33:24.297375Z",
     "shell.execute_reply": "2025-05-22T07:33:24.296210Z"
    },
    "papermill": {
     "duration": 0.020784,
     "end_time": "2025-05-22T07:33:24.298788",
     "exception": false,
     "start_time": "2025-05-22T07:33:24.278004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Country</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Job Requirements</th>\n",
       "      <th>Work Type</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QA Engineer (ShopeePay) - Sea Labs</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Be involved in whole development life cycle an...</td>\n",
       "      <td>Functional testing via grey-box and white-box ...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/qa-engineer-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QA Engineer (Credit) - Sea Labs</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Be involved in whole development life cycle an...</td>\n",
       "      <td>Functional testing via grey-box and white-box ...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/qa-engineer-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quality Assurance Engineer</td>\n",
       "      <td>Traveloka</td>\n",
       "      <td>Jakarta Metropolitan Area</td>\n",
       "      <td>Jakarta Metropolitan Area</td>\n",
       "      <td>Work with Product Managers, Engineering team, ...</td>\n",
       "      <td>Create test plan and test cases based on the p...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/quality-assu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QA Tester (Manual)</td>\n",
       "      <td>Jubelio</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Understand software Development Life Cycle</td>\n",
       "      <td>Create test case API positif and negative | Yo...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/qa-tester-ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quality Assurance Tester</td>\n",
       "      <td>PT. Lintas Teknologi Indonesia</td>\n",
       "      <td>Depok, Yogyakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Bachelor Degree is a MUST! | 2+ years experien...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/quality-assu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Expert QA Engineer (Credit) - Sea Labs</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Manage the feature testing and/or regular regr...</td>\n",
       "      <td>Continuous improvement and research of testing...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/expert-qa-en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Expert QA Engineer (Credit) - Sea Labs</td>\n",
       "      <td>Sea</td>\n",
       "      <td>Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Manage the feature testing and/or regular regr...</td>\n",
       "      <td>Continuous improvement and research of testing...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/expert-qa-en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>QA Engineer</td>\n",
       "      <td>ZettaByte Pte Ltd</td>\n",
       "      <td>Yogyakarta, Yogyakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Diploma or Bachelor’s degree in Computer Scien...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/qa-engineer-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>QA Engineer 2 (Mekari Jurnal)</td>\n",
       "      <td>Mekari</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Define, describe, review test cases for all re...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/qa-engineer-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>Quality Assurance Engineer (Contract Based)</td>\n",
       "      <td>ParagonCorp</td>\n",
       "      <td>Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Create detailed, comprehensive, and well-struc...</td>\n",
       "      <td>Review requirements, specifications, and techn...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/quality-assu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Title  \\\n",
       "0             QA Engineer (ShopeePay) - Sea Labs   \n",
       "1                QA Engineer (Credit) - Sea Labs   \n",
       "2                     Quality Assurance Engineer   \n",
       "3                             QA Tester (Manual)   \n",
       "4                       Quality Assurance Tester   \n",
       "..                                           ...   \n",
       "235       Expert QA Engineer (Credit) - Sea Labs   \n",
       "236       Expert QA Engineer (Credit) - Sea Labs   \n",
       "237                                  QA Engineer   \n",
       "238                QA Engineer 2 (Mekari Jurnal)   \n",
       "239  Quality Assurance Engineer (Contract Based)   \n",
       "\n",
       "                            Company                           Location  \\\n",
       "0                            Shopee                 Jakarta, Indonesia   \n",
       "1                            Shopee                 Jakarta, Indonesia   \n",
       "2                         Traveloka          Jakarta Metropolitan Area   \n",
       "3                           Jubelio        Jakarta, Jakarta, Indonesia   \n",
       "4    PT. Lintas Teknologi Indonesia       Depok, Yogyakarta, Indonesia   \n",
       "..                              ...                                ...   \n",
       "235                          Shopee                 Jakarta, Indonesia   \n",
       "236                             Sea                 Jakarta, Indonesia   \n",
       "237               ZettaByte Pte Ltd  Yogyakarta, Yogyakarta, Indonesia   \n",
       "238                          Mekari        Jakarta, Jakarta, Indonesia   \n",
       "239                     ParagonCorp                 Jakarta, Indonesia   \n",
       "\n",
       "                       Country  \\\n",
       "0                    Indonesia   \n",
       "1                    Indonesia   \n",
       "2    Jakarta Metropolitan Area   \n",
       "3                    Indonesia   \n",
       "4                    Indonesia   \n",
       "..                         ...   \n",
       "235                  Indonesia   \n",
       "236                  Indonesia   \n",
       "237                  Indonesia   \n",
       "238                  Indonesia   \n",
       "239                  Indonesia   \n",
       "\n",
       "                                       Job Description  \\\n",
       "0    Be involved in whole development life cycle an...   \n",
       "1    Be involved in whole development life cycle an...   \n",
       "2    Work with Product Managers, Engineering team, ...   \n",
       "3           Understand software Development Life Cycle   \n",
       "4                                            Not Found   \n",
       "..                                                 ...   \n",
       "235  Manage the feature testing and/or regular regr...   \n",
       "236  Manage the feature testing and/or regular regr...   \n",
       "237                                          Not Found   \n",
       "238                                          Not Found   \n",
       "239  Create detailed, comprehensive, and well-struc...   \n",
       "\n",
       "                                      Job Requirements  Work Type  \\\n",
       "0    Functional testing via grey-box and white-box ...  Not Found   \n",
       "1    Functional testing via grey-box and white-box ...  Not Found   \n",
       "2    Create test plan and test cases based on the p...  Not Found   \n",
       "3    Create test case API positif and negative | Yo...  Not Found   \n",
       "4    Bachelor Degree is a MUST! | 2+ years experien...  Not Found   \n",
       "..                                                 ...        ...   \n",
       "235  Continuous improvement and research of testing...  Not Found   \n",
       "236  Continuous improvement and research of testing...  Not Found   \n",
       "237  Diploma or Bachelor’s degree in Computer Scien...  Not Found   \n",
       "238  Define, describe, review test cases for all re...  Not Found   \n",
       "239  Review requirements, specifications, and techn...  Not Found   \n",
       "\n",
       "                                                  Link  \n",
       "0    https://id.linkedin.com/jobs/view/qa-engineer-...  \n",
       "1    https://id.linkedin.com/jobs/view/qa-engineer-...  \n",
       "2    https://id.linkedin.com/jobs/view/quality-assu...  \n",
       "3    https://id.linkedin.com/jobs/view/qa-tester-ma...  \n",
       "4    https://id.linkedin.com/jobs/view/quality-assu...  \n",
       "..                                                 ...  \n",
       "235  https://id.linkedin.com/jobs/view/expert-qa-en...  \n",
       "236  https://id.linkedin.com/jobs/view/expert-qa-en...  \n",
       "237  https://id.linkedin.com/jobs/view/qa-engineer-...  \n",
       "238  https://id.linkedin.com/jobs/view/qa-engineer-...  \n",
       "239  https://id.linkedin.com/jobs/view/quality-assu...  \n",
       "\n",
       "[240 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.DataFrame({\n",
    "    \"Title\": titles,\n",
    "    \"Company\": company_name,\n",
    "    \"Location\": locations,\n",
    "    \"Country\": countries,\n",
    "    \"Job Description\": job_description,\n",
    "    \"Job Requirements\": job_requirement,\n",
    "    \"Work Type\" : work_types,\n",
    "    \"Link\": links\n",
    "})\n",
    "\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a24ad9c",
   "metadata": {
    "papermill": {
     "duration": 0.067876,
     "end_time": "2025-05-22T07:33:24.379182",
     "exception": false,
     "start_time": "2025-05-22T07:33:24.311306",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Fullstack Developer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ed7ebe3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T07:33:24.394097Z",
     "iopub.status.busy": "2025-05-22T07:33:24.393460Z",
     "iopub.status.idle": "2025-05-22T07:33:24.396770Z",
     "shell.execute_reply": "2025-05-22T07:33:24.396294Z"
    },
    "papermill": {
     "duration": 0.011781,
     "end_time": "2025-05-22T07:33:24.397793",
     "exception": false,
     "start_time": "2025-05-22T07:33:24.386012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "url_fullstack = \"https://www.linkedin.com/jobs/search/?currentJobId=4227359993&geoId=102478259&keywords=fullstack%20developer&refresh=true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac19a94e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T07:33:24.411898Z",
     "iopub.status.busy": "2025-05-22T07:33:24.411727Z",
     "iopub.status.idle": "2025-05-22T07:39:24.391370Z",
     "shell.execute_reply": "2025-05-22T07:39:24.390700Z"
    },
    "papermill": {
     "duration": 359.988251,
     "end_time": "2025-05-22T07:39:24.392822",
     "exception": false,
     "start_time": "2025-05-22T07:33:24.404571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "locations = []\n",
    "titles = []\n",
    "countries = []    \n",
    "links = []\n",
    "company_name = []\n",
    "job_description = []\n",
    "job_requirement = []\n",
    "work_types = []\n",
    "\n",
    "for i in range(0, 100, 25):\n",
    "    url = url_fullstack + \"&start=\" + str(i)\n",
    "    request = requests.get(url)\n",
    "    soup = BeautifulSoup(request.text, 'html.parser')\n",
    "\n",
    "    # Location\n",
    "    location = soup.findAll(\"span\", {\"class\": \"job-search-card__location\"})\n",
    "    for loc in location:\n",
    "        locations.append(loc.text.replace(\"\\n\", \" \").strip())\n",
    "\n",
    "    # Title\n",
    "    title = soup.findAll(\"h3\", {\"class\": \"base-search-card__title\"})\n",
    "    for t in title:\n",
    "        titles.append(t.text.replace(\"\\n\", \" \").strip())\n",
    "\n",
    "    # Country\n",
    "    for c in location:\n",
    "        countries.append(c.text.replace(\"\\n\", \" \").strip().split(',')[-1])\n",
    "\n",
    "    # Job links\n",
    "    job_links = soup.findAll(\"a\", {\"class\": \"base-card__full-link\"})\n",
    "    for link in job_links:\n",
    "        links.append(link[\"href\"])\n",
    "\n",
    "    # Company names\n",
    "    names = soup.findAll(\"a\", {\"class\": \"hidden-nested-link\"})\n",
    "    for name in names:\n",
    "        company_name.append(name.text.replace(\"\\n\", \" \").strip())\n",
    "\n",
    "# Keywords\n",
    "desc_keywords = ['responsibilities', 'responsibilities:', 'what you’ll do', 'what you will do', 'deskripsi', 'tugas', 'role', 'job description:', 'job description', \n",
    "                 'your main duties in flying with us', 'your impact', \"you’ll get to\"]\n",
    "req_keywords = ['requirement', 'requirement:', 'requirements', 'requirements:', 'qualification', 'qualification:', 'qualifications', 'qualifications:', 'kualifikasi',\n",
    "                'what you’ll need', 'what you will need', 'you should have', 'skills', 'experience', 'job requirements', 'mandatory belongings that you must prepare', \n",
    "                'who we look for', \"you’ll need to succeed\", 'what this role needs', 'kriteria']\n",
    "\n",
    "for link in links:\n",
    "    try:\n",
    "        job_page = requests.get(link)\n",
    "        job_soup = BeautifulSoup(job_page.text, 'html.parser')\n",
    "\n",
    "        # Extract work type\n",
    "        work_type_found = \"Not Found\"\n",
    "        preference_button = job_soup.find(\"button\", class_=\"job-details-preferences-and-skills\")\n",
    "        if preference_button:\n",
    "            pill_divs = preference_button.find_all(\"div\", class_=\"job-details-preferences-and-skills__pill\")\n",
    "            for pill in pill_divs:\n",
    "                span = pill.find(\"span\", class_=\"ui-label ui-label--accent-3 text-body-small\")\n",
    "                if span and span.text.strip() in [\"Remote\", \"On-site\", \"Hybrid\"]:\n",
    "                    work_type_found = span.text.strip()\n",
    "                    break\n",
    "        work_types.append(work_type_found)\n",
    "\n",
    "        # Extract job description & requirements\n",
    "        desc_block = job_soup.find(\"div\", {\"class\": \"show-more-less-html__markup\"})\n",
    "        if desc_block:\n",
    "            items = desc_block.find_all(\"li\")\n",
    "            li_texts = [li.text.strip() for li in items]\n",
    "\n",
    "            desc_part = []\n",
    "            req_part = []\n",
    "\n",
    "            for li_text in li_texts:\n",
    "                text_lower = li_text.lower()\n",
    "                \n",
    "                if any(k in text_lower for k in req_keywords):\n",
    "                    req_part.append(li_text)\n",
    "                elif any(k in text_lower for k in desc_keywords):\n",
    "                    desc_part.append(li_text)\n",
    "                else:\n",
    "                    if any(word in text_lower for word in ['analyze', 'develop', 'manage', 'design', 'plan']):\n",
    "                        desc_part.append(li_text)\n",
    "                    else:\n",
    "                        req_part.append(li_text)\n",
    "\n",
    "            job_description.append(\" | \".join(desc_part) if desc_part else \"Not Found\")\n",
    "            job_requirement.append(\" | \".join(req_part) if req_part else \"Not Found\")\n",
    "        else:\n",
    "            job_description.append(\"Not Found\")\n",
    "            job_requirement.append(\"Not Found\")\n",
    "\n",
    "        time.sleep(1)\n",
    "    except Exception as e:\n",
    "        job_description.append(\"Error: \" + str(e))\n",
    "        job_requirement.append(\"Error: \" + str(e))\n",
    "        work_types.append(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9df5a933",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T07:39:24.408066Z",
     "iopub.status.busy": "2025-05-22T07:39:24.407694Z",
     "iopub.status.idle": "2025-05-22T07:39:24.411312Z",
     "shell.execute_reply": "2025-05-22T07:39:24.410639Z"
    },
    "papermill": {
     "duration": 0.012126,
     "end_time": "2025-05-22T07:39:24.412506",
     "exception": false,
     "start_time": "2025-05-22T07:39:24.400380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_len = min(len(titles), len(locations), len(countries), len(links), len(company_name), len(job_description), len(job_requirement))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c07ae37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T07:39:24.426760Z",
     "iopub.status.busy": "2025-05-22T07:39:24.426572Z",
     "iopub.status.idle": "2025-05-22T07:39:24.430304Z",
     "shell.execute_reply": "2025-05-22T07:39:24.429565Z"
    },
    "papermill": {
     "duration": 0.012076,
     "end_time": "2025-05-22T07:39:24.431349",
     "exception": false,
     "start_time": "2025-05-22T07:39:24.419273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "titles = titles[:min_len]\n",
    "locations = locations[:min_len]\n",
    "countries = countries[:min_len]\n",
    "links = links[:min_len]\n",
    "company_name = company_name[:min_len]\n",
    "job_description = job_description[:min_len]\n",
    "job_requirement = job_requirement[:min_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9abc0d7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T07:39:24.445754Z",
     "iopub.status.busy": "2025-05-22T07:39:24.445567Z",
     "iopub.status.idle": "2025-05-22T07:39:24.456948Z",
     "shell.execute_reply": "2025-05-22T07:39:24.456311Z"
    },
    "papermill": {
     "duration": 0.019911,
     "end_time": "2025-05-22T07:39:24.457973",
     "exception": false,
     "start_time": "2025-05-22T07:39:24.438062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Country</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Job Requirements</th>\n",
       "      <th>Work Type</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fullstack Developer</td>\n",
       "      <td>PT Astra International Tbk</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Membuat, memperbarui, dan memantau tugas yang ...</td>\n",
       "      <td>Membangun front-end web dan back-end API (fitu...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/fullstack-de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Application Software Developer</td>\n",
       "      <td>PT Sinergy Informasi Pratama</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>1 hingga 2 tahun pengalaman sebagai Fullstack ...</td>\n",
       "      <td>Min. S1 jurusan IT, Rekayasa Perangkat Lunak, ...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/application-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fullstack Developer</td>\n",
       "      <td>PT Astra International Tbk</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Memahami Development di Azure Cloud Environment</td>\n",
       "      <td>Merancang, mendesain, mengembangkan dan memodi...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/fullstack-de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fullstack Developer (Site: Sumatera Selatan)</td>\n",
       "      <td>PT. Metrodata Electronics Tbk.</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Design, Develop, Analyze, troubleshooting rela...</td>\n",
       "      <td>Conduct analysis and problem solving of applic...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/fullstack-de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Software Engineer (Fullstack)</td>\n",
       "      <td>Sprout Digital Labs</td>\n",
       "      <td>Tangerang Regency, Banten, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>You will be deeply engaged in the full develop...</td>\n",
       "      <td>Provide technical leadership in a fast-moving,...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/software-eng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>UI Solution Engineer 1 (Mekari Officeless)</td>\n",
       "      <td>Asiatek Solusi Indonesia</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Back-End Web Development and Full-Stack Develo...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/fullstack-de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Remote Nextjs Fullstack Developer</td>\n",
       "      <td>Agnos Inc.</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>We work with our clients to revolutionize thei...</td>\n",
       "      <td>Our current client is focused on transforming ...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/lead-softwar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>Java Developer Backend Developer</td>\n",
       "      <td>PT Hermes Solusi Integrasi</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Experience and understand on developing busine...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/senior-fulls...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Lead Software Engineer (RoR Fullstack Engineer...</td>\n",
       "      <td>PT. Digital Netwerk Venture Indonesia | The Ne...</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/full-stack-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>Java Fullstack Developer</td>\n",
       "      <td>Mekari</td>\n",
       "      <td>Semarang, Central Java, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Customizing vertical product based on clients’...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/solution-imp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "0                                  Fullstack Developer   \n",
       "1                       Application Software Developer   \n",
       "2                                  Fullstack Developer   \n",
       "3         Fullstack Developer (Site: Sumatera Selatan)   \n",
       "4                        Software Engineer (Fullstack)   \n",
       "..                                                 ...   \n",
       "223         UI Solution Engineer 1 (Mekari Officeless)   \n",
       "224                  Remote Nextjs Fullstack Developer   \n",
       "225                   Java Developer Backend Developer   \n",
       "226  Lead Software Engineer (RoR Fullstack Engineer...   \n",
       "227                           Java Fullstack Developer   \n",
       "\n",
       "                                               Company  \\\n",
       "0                           PT Astra International Tbk   \n",
       "1                         PT Sinergy Informasi Pratama   \n",
       "2                           PT Astra International Tbk   \n",
       "3                       PT. Metrodata Electronics Tbk.   \n",
       "4                                  Sprout Digital Labs   \n",
       "..                                                 ...   \n",
       "223                           Asiatek Solusi Indonesia   \n",
       "224                                         Agnos Inc.   \n",
       "225                         PT Hermes Solusi Integrasi   \n",
       "226  PT. Digital Netwerk Venture Indonesia | The Ne...   \n",
       "227                                             Mekari   \n",
       "\n",
       "                                 Location     Country  \\\n",
       "0             Jakarta, Jakarta, Indonesia   Indonesia   \n",
       "1             Jakarta, Jakarta, Indonesia   Indonesia   \n",
       "2             Jakarta, Jakarta, Indonesia   Indonesia   \n",
       "3             Jakarta, Jakarta, Indonesia   Indonesia   \n",
       "4    Tangerang Regency, Banten, Indonesia   Indonesia   \n",
       "..                                    ...         ...   \n",
       "223           Jakarta, Jakarta, Indonesia   Indonesia   \n",
       "224                             Indonesia   Indonesia   \n",
       "225           Jakarta, Jakarta, Indonesia   Indonesia   \n",
       "226                             Indonesia   Indonesia   \n",
       "227     Semarang, Central Java, Indonesia   Indonesia   \n",
       "\n",
       "                                       Job Description  \\\n",
       "0    Membuat, memperbarui, dan memantau tugas yang ...   \n",
       "1    1 hingga 2 tahun pengalaman sebagai Fullstack ...   \n",
       "2      Memahami Development di Azure Cloud Environment   \n",
       "3    Design, Develop, Analyze, troubleshooting rela...   \n",
       "4    You will be deeply engaged in the full develop...   \n",
       "..                                                 ...   \n",
       "223                                          Not Found   \n",
       "224  We work with our clients to revolutionize thei...   \n",
       "225                                          Not Found   \n",
       "226                                          Not Found   \n",
       "227                                          Not Found   \n",
       "\n",
       "                                      Job Requirements  Work Type  \\\n",
       "0    Membangun front-end web dan back-end API (fitu...  Not Found   \n",
       "1    Min. S1 jurusan IT, Rekayasa Perangkat Lunak, ...  Not Found   \n",
       "2    Merancang, mendesain, mengembangkan dan memodi...  Not Found   \n",
       "3    Conduct analysis and problem solving of applic...  Not Found   \n",
       "4    Provide technical leadership in a fast-moving,...  Not Found   \n",
       "..                                                 ...        ...   \n",
       "223  Back-End Web Development and Full-Stack Develo...  Not Found   \n",
       "224  Our current client is focused on transforming ...  Not Found   \n",
       "225  Experience and understand on developing busine...  Not Found   \n",
       "226                                          Not Found  Not Found   \n",
       "227  Customizing vertical product based on clients’...  Not Found   \n",
       "\n",
       "                                                  Link  \n",
       "0    https://id.linkedin.com/jobs/view/fullstack-de...  \n",
       "1    https://id.linkedin.com/jobs/view/application-...  \n",
       "2    https://id.linkedin.com/jobs/view/fullstack-de...  \n",
       "3    https://id.linkedin.com/jobs/view/fullstack-de...  \n",
       "4    https://id.linkedin.com/jobs/view/software-eng...  \n",
       "..                                                 ...  \n",
       "223  https://id.linkedin.com/jobs/view/fullstack-de...  \n",
       "224  https://id.linkedin.com/jobs/view/lead-softwar...  \n",
       "225  https://id.linkedin.com/jobs/view/senior-fulls...  \n",
       "226  https://id.linkedin.com/jobs/view/full-stack-e...  \n",
       "227  https://id.linkedin.com/jobs/view/solution-imp...  \n",
       "\n",
       "[228 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = pd.DataFrame({\n",
    "    \"Title\": titles,\n",
    "    \"Company\": company_name,\n",
    "    \"Location\": locations,\n",
    "    \"Country\": countries,\n",
    "    \"Job Description\": job_description,\n",
    "    \"Job Requirements\": job_requirement,\n",
    "    \"Work Type\" : work_types,\n",
    "    \"Link\": links\n",
    "})\n",
    "\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc838df",
   "metadata": {
    "papermill": {
     "duration": 0.006906,
     "end_time": "2025-05-22T07:39:24.471949",
     "exception": false,
     "start_time": "2025-05-22T07:39:24.465043",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# UI/UX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a1ab9b7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T07:39:24.486541Z",
     "iopub.status.busy": "2025-05-22T07:39:24.486344Z",
     "iopub.status.idle": "2025-05-22T07:39:24.489332Z",
     "shell.execute_reply": "2025-05-22T07:39:24.488665Z"
    },
    "papermill": {
     "duration": 0.011419,
     "end_time": "2025-05-22T07:39:24.490358",
     "exception": false,
     "start_time": "2025-05-22T07:39:24.478939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "url_uiux = \"https://www.linkedin.com/jobs/search/?currentJobId=4227359993&geoId=102478259&keywords=ui%20ux&refresh=true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "334584cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T07:39:24.505212Z",
     "iopub.status.busy": "2025-05-22T07:39:24.504990Z",
     "iopub.status.idle": "2025-05-22T07:46:10.482720Z",
     "shell.execute_reply": "2025-05-22T07:46:10.482124Z"
    },
    "papermill": {
     "duration": 405.98687,
     "end_time": "2025-05-22T07:46:10.484148",
     "exception": false,
     "start_time": "2025-05-22T07:39:24.497278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "locations = []\n",
    "titles = []\n",
    "countries = []    \n",
    "links = []\n",
    "company_name = []\n",
    "job_description = []\n",
    "job_requirement = []\n",
    "work_types = []\n",
    "\n",
    "for i in range(0, 100, 25):\n",
    "    url = url_uiux + \"&start=\" + str(i)\n",
    "    request = requests.get(url)\n",
    "    soup = BeautifulSoup(request.text, 'html.parser')\n",
    "\n",
    "    # Location\n",
    "    location = soup.findAll(\"span\", {\"class\": \"job-search-card__location\"})\n",
    "    for loc in location:\n",
    "        locations.append(loc.text.replace(\"\\n\", \" \").strip())\n",
    "\n",
    "    # Title\n",
    "    title = soup.findAll(\"h3\", {\"class\": \"base-search-card__title\"})\n",
    "    for t in title:\n",
    "        titles.append(t.text.replace(\"\\n\", \" \").strip())\n",
    "\n",
    "    # Country\n",
    "    for c in location:\n",
    "        countries.append(c.text.replace(\"\\n\", \" \").strip().split(',')[-1])\n",
    "\n",
    "    # Job links\n",
    "    job_links = soup.findAll(\"a\", {\"class\": \"base-card__full-link\"})\n",
    "    for link in job_links:\n",
    "        links.append(link[\"href\"])\n",
    "\n",
    "    # Company names\n",
    "    names = soup.findAll(\"a\", {\"class\": \"hidden-nested-link\"})\n",
    "    for name in names:\n",
    "        company_name.append(name.text.replace(\"\\n\", \" \").strip())\n",
    "\n",
    "# Keywords\n",
    "desc_keywords = ['responsibilities', 'responsibilities:', 'what you’ll do', 'what you will do', 'deskripsi', 'tugas', 'role', 'job description:', 'job description', \n",
    "                 'your main duties in flying with us', 'your impact', \"you’ll get to\"]\n",
    "req_keywords = ['requirement', 'requirement:', 'requirements', 'requirements:', 'qualification', 'qualification:', 'qualifications', 'qualifications:', 'kualifikasi',\n",
    "                'what you’ll need', 'what you will need', 'you should have', 'skills', 'experience', 'job requirements', 'mandatory belongings that you must prepare', \n",
    "                'who we look for', \"you’ll need to succeed\", 'what this role needs', 'kriteria']\n",
    "\n",
    "for link in links:\n",
    "    try:\n",
    "        job_page = requests.get(link)\n",
    "        job_soup = BeautifulSoup(job_page.text, 'html.parser')\n",
    "\n",
    "        # Extract work type\n",
    "        work_type_found = \"Not Found\"\n",
    "        preference_button = job_soup.find(\"button\", class_=\"job-details-preferences-and-skills\")\n",
    "        if preference_button:\n",
    "            pill_divs = preference_button.find_all(\"div\", class_=\"job-details-preferences-and-skills__pill\")\n",
    "            for pill in pill_divs:\n",
    "                span = pill.find(\"span\", class_=\"ui-label ui-label--accent-3 text-body-small\")\n",
    "                if span and span.text.strip() in [\"Remote\", \"On-site\", \"Hybrid\"]:\n",
    "                    work_type_found = span.text.strip()\n",
    "                    break\n",
    "        work_types.append(work_type_found)\n",
    "\n",
    "        # Extract job description & requirements\n",
    "        desc_block = job_soup.find(\"div\", {\"class\": \"show-more-less-html__markup\"})\n",
    "        if desc_block:\n",
    "            items = desc_block.find_all(\"li\")\n",
    "            li_texts = [li.text.strip() for li in items]\n",
    "\n",
    "            desc_part = []\n",
    "            req_part = []\n",
    "\n",
    "            for li_text in li_texts:\n",
    "                text_lower = li_text.lower()\n",
    "                \n",
    "                if any(k in text_lower for k in req_keywords):\n",
    "                    req_part.append(li_text)\n",
    "                elif any(k in text_lower for k in desc_keywords):\n",
    "                    desc_part.append(li_text)\n",
    "                else:\n",
    "                    if any(word in text_lower for word in ['analyze', 'develop', 'manage', 'design', 'plan']):\n",
    "                        desc_part.append(li_text)\n",
    "                    else:\n",
    "                        req_part.append(li_text)\n",
    "\n",
    "            job_description.append(\" | \".join(desc_part) if desc_part else \"Not Found\")\n",
    "            job_requirement.append(\" | \".join(req_part) if req_part else \"Not Found\")\n",
    "        else:\n",
    "            job_description.append(\"Not Found\")\n",
    "            job_requirement.append(\"Not Found\")\n",
    "\n",
    "        time.sleep(1)\n",
    "    except Exception as e:\n",
    "        job_description.append(\"Error: \" + str(e))\n",
    "        job_requirement.append(\"Error: \" + str(e))\n",
    "        work_types.append(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afa08a29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T07:46:10.500038Z",
     "iopub.status.busy": "2025-05-22T07:46:10.499825Z",
     "iopub.status.idle": "2025-05-22T07:46:10.511620Z",
     "shell.execute_reply": "2025-05-22T07:46:10.511097Z"
    },
    "papermill": {
     "duration": 0.020622,
     "end_time": "2025-05-22T07:46:10.512760",
     "exception": false,
     "start_time": "2025-05-22T07:46:10.492138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Country</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Job Requirements</th>\n",
       "      <th>Work Type</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Product Intern</td>\n",
       "      <td>INDICO by Telkomsel</td>\n",
       "      <td>Jakarta Metropolitan Area</td>\n",
       "      <td>Jakarta Metropolitan Area</td>\n",
       "      <td>Assist the product team in product development...</td>\n",
       "      <td>Draft and assist in the creation of Product Re...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/product-inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Digital Marketing Analyst</td>\n",
       "      <td>PT ASTRA OTOPARTS Tbk</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Manage B2B Digtal Business in terms of Product...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/digital-mark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UI/UX Consultant</td>\n",
       "      <td>EY</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Provide design guideline standard to ensure go...</td>\n",
       "      <td>Provide guidance on the implementation of UX r...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/ui-ux-consul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UI/UX Designer</td>\n",
       "      <td>Sprout Digital Labs</td>\n",
       "      <td>Tangerang, Banten, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Develop understanding of the end users of the ...</td>\n",
       "      <td>Responsible for understanding project brief an...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/ui-ux-design...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UI / UX Designer</td>\n",
       "      <td>PT Astra International Tbk</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Mengembangkan dan mendesign interface aplikasi...</td>\n",
       "      <td>Memiliki pengalaman 1-2 tahun di bidang terseb...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/ui-ux-design...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Website Designer</td>\n",
       "      <td>Reel Unlimited</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Design visually appealing and user-friendly we...</td>\n",
       "      <td>Create responsive layouts that work seamlessly...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/website-desi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>UX Content Analyst</td>\n",
       "      <td>Mobbin</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Annotate screens and flows with information ab...</td>\n",
       "      <td>Acquire and prepare content on a weekly basis,...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/ux-content-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Jr. Product Manager</td>\n",
       "      <td>Synapsis</td>\n",
       "      <td>Gambir, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Conduct in-depth research on user needs, pain ...</td>\n",
       "      <td>Define product requirements and propose new fe...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/jr-product-m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>Senior UI/UX Designer</td>\n",
       "      <td>Mitramas Infosys Global</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Develop the product’s look and feel, including...</td>\n",
       "      <td>Conduct research about website and app UI and ...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/senior-ui-ux...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>Product Lead</td>\n",
       "      <td>Bibit.id</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Manage and own the full spectrum of the produc...</td>\n",
       "      <td>Lead the Product Team with a clear technical v...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/product-lead...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Title                     Company  \\\n",
       "0               Product Intern         INDICO by Telkomsel   \n",
       "1    Digital Marketing Analyst       PT ASTRA OTOPARTS Tbk   \n",
       "2             UI/UX Consultant                          EY   \n",
       "3               UI/UX Designer         Sprout Digital Labs   \n",
       "4             UI / UX Designer  PT Astra International Tbk   \n",
       "..                         ...                         ...   \n",
       "235           Website Designer              Reel Unlimited   \n",
       "236         UX Content Analyst                      Mobbin   \n",
       "237        Jr. Product Manager                    Synapsis   \n",
       "238      Senior UI/UX Designer     Mitramas Infosys Global   \n",
       "239               Product Lead                    Bibit.id   \n",
       "\n",
       "                         Location                    Country  \\\n",
       "0       Jakarta Metropolitan Area  Jakarta Metropolitan Area   \n",
       "1     Jakarta, Jakarta, Indonesia                  Indonesia   \n",
       "2     Jakarta, Jakarta, Indonesia                  Indonesia   \n",
       "3    Tangerang, Banten, Indonesia                  Indonesia   \n",
       "4     Jakarta, Jakarta, Indonesia                  Indonesia   \n",
       "..                            ...                        ...   \n",
       "235                     Indonesia                  Indonesia   \n",
       "236   Jakarta, Jakarta, Indonesia                  Indonesia   \n",
       "237    Gambir, Jakarta, Indonesia                  Indonesia   \n",
       "238   Jakarta, Jakarta, Indonesia                  Indonesia   \n",
       "239   Jakarta, Jakarta, Indonesia                  Indonesia   \n",
       "\n",
       "                                       Job Description  \\\n",
       "0    Assist the product team in product development...   \n",
       "1                                            Not Found   \n",
       "2    Provide design guideline standard to ensure go...   \n",
       "3    Develop understanding of the end users of the ...   \n",
       "4    Mengembangkan dan mendesign interface aplikasi...   \n",
       "..                                                 ...   \n",
       "235  Design visually appealing and user-friendly we...   \n",
       "236  Annotate screens and flows with information ab...   \n",
       "237  Conduct in-depth research on user needs, pain ...   \n",
       "238  Develop the product’s look and feel, including...   \n",
       "239  Manage and own the full spectrum of the produc...   \n",
       "\n",
       "                                      Job Requirements  Work Type  \\\n",
       "0    Draft and assist in the creation of Product Re...  Not Found   \n",
       "1    Manage B2B Digtal Business in terms of Product...  Not Found   \n",
       "2    Provide guidance on the implementation of UX r...  Not Found   \n",
       "3    Responsible for understanding project brief an...  Not Found   \n",
       "4    Memiliki pengalaman 1-2 tahun di bidang terseb...  Not Found   \n",
       "..                                                 ...        ...   \n",
       "235  Create responsive layouts that work seamlessly...  Not Found   \n",
       "236  Acquire and prepare content on a weekly basis,...  Not Found   \n",
       "237  Define product requirements and propose new fe...  Not Found   \n",
       "238  Conduct research about website and app UI and ...  Not Found   \n",
       "239  Lead the Product Team with a clear technical v...  Not Found   \n",
       "\n",
       "                                                  Link  \n",
       "0    https://id.linkedin.com/jobs/view/product-inte...  \n",
       "1    https://id.linkedin.com/jobs/view/digital-mark...  \n",
       "2    https://id.linkedin.com/jobs/view/ui-ux-consul...  \n",
       "3    https://id.linkedin.com/jobs/view/ui-ux-design...  \n",
       "4    https://id.linkedin.com/jobs/view/ui-ux-design...  \n",
       "..                                                 ...  \n",
       "235  https://id.linkedin.com/jobs/view/website-desi...  \n",
       "236  https://id.linkedin.com/jobs/view/ux-content-a...  \n",
       "237  https://id.linkedin.com/jobs/view/jr-product-m...  \n",
       "238  https://id.linkedin.com/jobs/view/senior-ui-ux...  \n",
       "239  https://id.linkedin.com/jobs/view/product-lead...  \n",
       "\n",
       "[240 rows x 8 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5 = pd.DataFrame({\n",
    "    \"Title\": titles,\n",
    "    \"Company\": company_name,\n",
    "    \"Location\": locations,\n",
    "    \"Country\": countries,\n",
    "    \"Job Description\": job_description,\n",
    "    \"Job Requirements\": job_requirement,\n",
    "    \"Work Type\" : work_types,\n",
    "    \"Link\": links\n",
    "})\n",
    "\n",
    "df5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39832a3f",
   "metadata": {
    "papermill": {
     "duration": 0.007205,
     "end_time": "2025-05-22T07:46:10.527808",
     "exception": false,
     "start_time": "2025-05-22T07:46:10.520603",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cybersecurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f02178b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T07:46:10.543144Z",
     "iopub.status.busy": "2025-05-22T07:46:10.542956Z",
     "iopub.status.idle": "2025-05-22T07:46:10.545705Z",
     "shell.execute_reply": "2025-05-22T07:46:10.545228Z"
    },
    "papermill": {
     "duration": 0.011507,
     "end_time": "2025-05-22T07:46:10.546700",
     "exception": false,
     "start_time": "2025-05-22T07:46:10.535193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "url_cyber = \"https://www.linkedin.com/jobs/search/?currentJobId=4215815843&geoId=102478259&keywords=cybersecurity&refresh=true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eab5e4ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T07:46:10.562537Z",
     "iopub.status.busy": "2025-05-22T07:46:10.562347Z",
     "iopub.status.idle": "2025-05-22T07:52:59.945046Z",
     "shell.execute_reply": "2025-05-22T07:52:59.944495Z"
    },
    "papermill": {
     "duration": 409.392382,
     "end_time": "2025-05-22T07:52:59.946589",
     "exception": false,
     "start_time": "2025-05-22T07:46:10.554207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "locations = []\n",
    "titles = []\n",
    "countries = []    \n",
    "links = []\n",
    "company_name = []\n",
    "job_description = []\n",
    "job_requirement = []\n",
    "work_types = []\n",
    "\n",
    "for i in range(0, 100, 25):\n",
    "    url = url_cyber + \"&start=\" + str(i)\n",
    "    request = requests.get(url)\n",
    "    soup = BeautifulSoup(request.text, 'html.parser')\n",
    "\n",
    "    # Location\n",
    "    location = soup.findAll(\"span\", {\"class\": \"job-search-card__location\"})\n",
    "    for loc in location:\n",
    "        locations.append(loc.text.replace(\"\\n\", \" \").strip())\n",
    "\n",
    "    # Title\n",
    "    title = soup.findAll(\"h3\", {\"class\": \"base-search-card__title\"})\n",
    "    for t in title:\n",
    "        titles.append(t.text.replace(\"\\n\", \" \").strip())\n",
    "\n",
    "    # Country\n",
    "    for c in location:\n",
    "        countries.append(c.text.replace(\"\\n\", \" \").strip().split(',')[-1])\n",
    "\n",
    "    # Job links\n",
    "    job_links = soup.findAll(\"a\", {\"class\": \"base-card__full-link\"})\n",
    "    for link in job_links:\n",
    "        links.append(link[\"href\"])\n",
    "\n",
    "    # Company names\n",
    "    names = soup.findAll(\"a\", {\"class\": \"hidden-nested-link\"})\n",
    "    for name in names:\n",
    "        company_name.append(name.text.replace(\"\\n\", \" \").strip())\n",
    "\n",
    "# Keywords\n",
    "desc_keywords = ['responsibilities', 'responsibilities:', 'what you’ll do', 'what you will do', 'deskripsi', 'tugas', 'role', 'job description:', 'job description', \n",
    "                 'your main duties in flying with us', 'your impact', \"you’ll get to\"]\n",
    "req_keywords = ['requirement', 'requirement:', 'requirements', 'requirements:', 'qualification', 'qualification:', 'qualifications', 'qualifications:', 'kualifikasi',\n",
    "                'what you’ll need', 'what you will need', 'you should have', 'skills', 'experience', 'job requirements', 'mandatory belongings that you must prepare', \n",
    "                'who we look for', \"you’ll need to succeed\", 'what this role needs', 'kriteria']\n",
    "\n",
    "for link in links:\n",
    "    try:\n",
    "        job_page = requests.get(link)\n",
    "        job_soup = BeautifulSoup(job_page.text, 'html.parser')\n",
    "\n",
    "        # Extract work type\n",
    "        work_type_found = \"Not Found\"\n",
    "        preference_button = job_soup.find(\"button\", class_=\"job-details-preferences-and-skills\")\n",
    "        if preference_button:\n",
    "            pill_divs = preference_button.find_all(\"div\", class_=\"job-details-preferences-and-skills__pill\")\n",
    "            for pill in pill_divs:\n",
    "                span = pill.find(\"span\", class_=\"ui-label ui-label--accent-3 text-body-small\")\n",
    "                if span and span.text.strip() in [\"Remote\", \"On-site\", \"Hybrid\"]:\n",
    "                    work_type_found = span.text.strip()\n",
    "                    break\n",
    "        work_types.append(work_type_found)\n",
    "\n",
    "        # Extract job description & requirements\n",
    "        desc_block = job_soup.find(\"div\", {\"class\": \"show-more-less-html__markup\"})\n",
    "        if desc_block:\n",
    "            items = desc_block.find_all(\"li\")\n",
    "            li_texts = [li.text.strip() for li in items]\n",
    "\n",
    "            desc_part = []\n",
    "            req_part = []\n",
    "\n",
    "            for li_text in li_texts:\n",
    "                text_lower = li_text.lower()\n",
    "                \n",
    "                if any(k in text_lower for k in req_keywords):\n",
    "                    req_part.append(li_text)\n",
    "                elif any(k in text_lower for k in desc_keywords):\n",
    "                    desc_part.append(li_text)\n",
    "                else:\n",
    "                    if any(word in text_lower for word in ['analyze', 'develop', 'manage', 'design', 'plan']):\n",
    "                        desc_part.append(li_text)\n",
    "                    else:\n",
    "                        req_part.append(li_text)\n",
    "\n",
    "            job_description.append(\" | \".join(desc_part) if desc_part else \"Not Found\")\n",
    "            job_requirement.append(\" | \".join(req_part) if req_part else \"Not Found\")\n",
    "        else:\n",
    "            job_description.append(\"Not Found\")\n",
    "            job_requirement.append(\"Not Found\")\n",
    "\n",
    "        time.sleep(1)\n",
    "    except Exception as e:\n",
    "        job_description.append(\"Error: \" + str(e))\n",
    "        job_requirement.append(\"Error: \" + str(e))\n",
    "        work_types.append(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9767d2b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T07:52:59.963579Z",
     "iopub.status.busy": "2025-05-22T07:52:59.963349Z",
     "iopub.status.idle": "2025-05-22T07:52:59.975452Z",
     "shell.execute_reply": "2025-05-22T07:52:59.974794Z"
    },
    "papermill": {
     "duration": 0.021519,
     "end_time": "2025-05-22T07:52:59.976557",
     "exception": false,
     "start_time": "2025-05-22T07:52:59.955038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Country</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Job Requirements</th>\n",
       "      <th>Work Type</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cybersecurity Junior Consultant</td>\n",
       "      <td>EY</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Cyber Engineer – Managed Services | Managed Se...</td>\n",
       "      <td>Cyber Engineer – Red Team and Blue Team | Cybe...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/cybersecurit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Corporate Security Intern</td>\n",
       "      <td>PT Astra International Tbk</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Menganalisa Sistem Keamanan, Pengembangan SDM,...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/corporate-se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IT Security</td>\n",
       "      <td>PT. Astra Graphia Information Technology (AGIT)</td>\n",
       "      <td>Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Perform monitor, manage, and configure securit...</td>\n",
       "      <td>IT Security jaringan | Menguasai perangkat sec...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/it-security-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Information Technology Security Architect</td>\n",
       "      <td>PT Lion Super Indo</td>\n",
       "      <td>South Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Security Awareness: Champion a culture of secu...</td>\n",
       "      <td>Business Collaboration: Partner with business ...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/information-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IT Security</td>\n",
       "      <td>OCBC Indonesia</td>\n",
       "      <td>Tangerang, Banten, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Architecting and designing cybersecurity solut...</td>\n",
       "      <td>As a Security Architect - Create and enhance s...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/it-security-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Penetration Test Engineer – Blue Team L2 (WFO ...</td>\n",
       "      <td>SIGMATECH</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Collaborate with SOC, DevOps, and Infrastructu...</td>\n",
       "      <td>Perform regular penetration testing, vulnerabi...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/penetration-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Security Operation Manager</td>\n",
       "      <td>Traveloka</td>\n",
       "      <td>Jakarta Metropolitan Area</td>\n",
       "      <td>Jakarta Metropolitan Area</td>\n",
       "      <td>Manage Traveloka Security Operations team to r...</td>\n",
       "      <td>Provide expertise to help improve security dom...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/security-ope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>IT Security Specialist</td>\n",
       "      <td>Kredit Pintar</td>\n",
       "      <td>South Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Investigate and analyze security alerts, ident...</td>\n",
       "      <td>Monitor security systems and tools to detect a...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/it-security-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>Cyber Security Strategy Planning Head</td>\n",
       "      <td>PT Bank SMBC Indonesia Tbk</td>\n",
       "      <td>Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Coordinate with the Cyber Security Governance,...</td>\n",
       "      <td>In periodically and ad hoc basis, carry out th...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/cyber-securi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>Head of Information Technology</td>\n",
       "      <td>PT. Softex Indonesia</td>\n",
       "      <td>Tangerang, Banten, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Play a major role in the development of the or...</td>\n",
       "      <td>Drive strategic business value and innovation....</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/head-of-info...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "0                      Cybersecurity Junior Consultant   \n",
       "1                            Corporate Security Intern   \n",
       "2                                          IT Security   \n",
       "3            Information Technology Security Architect   \n",
       "4                                          IT Security   \n",
       "..                                                 ...   \n",
       "235  Penetration Test Engineer – Blue Team L2 (WFO ...   \n",
       "236                         Security Operation Manager   \n",
       "237                             IT Security Specialist   \n",
       "238              Cyber Security Strategy Planning Head   \n",
       "239                     Head of Information Technology   \n",
       "\n",
       "                                             Company  \\\n",
       "0                                                 EY   \n",
       "1                         PT Astra International Tbk   \n",
       "2    PT. Astra Graphia Information Technology (AGIT)   \n",
       "3                                 PT Lion Super Indo   \n",
       "4                                     OCBC Indonesia   \n",
       "..                                               ...   \n",
       "235                                        SIGMATECH   \n",
       "236                                        Traveloka   \n",
       "237                                    Kredit Pintar   \n",
       "238                       PT Bank SMBC Indonesia Tbk   \n",
       "239                             PT. Softex Indonesia   \n",
       "\n",
       "                              Location                    Country  \\\n",
       "0          Jakarta, Jakarta, Indonesia                  Indonesia   \n",
       "1          Jakarta, Jakarta, Indonesia                  Indonesia   \n",
       "2                   Jakarta, Indonesia                  Indonesia   \n",
       "3    South Jakarta, Jakarta, Indonesia                  Indonesia   \n",
       "4         Tangerang, Banten, Indonesia                  Indonesia   \n",
       "..                                 ...                        ...   \n",
       "235        Jakarta, Jakarta, Indonesia                  Indonesia   \n",
       "236          Jakarta Metropolitan Area  Jakarta Metropolitan Area   \n",
       "237  South Jakarta, Jakarta, Indonesia                  Indonesia   \n",
       "238                 Jakarta, Indonesia                  Indonesia   \n",
       "239       Tangerang, Banten, Indonesia                  Indonesia   \n",
       "\n",
       "                                       Job Description  \\\n",
       "0    Cyber Engineer – Managed Services | Managed Se...   \n",
       "1                                            Not Found   \n",
       "2    Perform monitor, manage, and configure securit...   \n",
       "3    Security Awareness: Champion a culture of secu...   \n",
       "4    Architecting and designing cybersecurity solut...   \n",
       "..                                                 ...   \n",
       "235  Collaborate with SOC, DevOps, and Infrastructu...   \n",
       "236  Manage Traveloka Security Operations team to r...   \n",
       "237  Investigate and analyze security alerts, ident...   \n",
       "238  Coordinate with the Cyber Security Governance,...   \n",
       "239  Play a major role in the development of the or...   \n",
       "\n",
       "                                      Job Requirements  Work Type  \\\n",
       "0    Cyber Engineer – Red Team and Blue Team | Cybe...  Not Found   \n",
       "1    Menganalisa Sistem Keamanan, Pengembangan SDM,...  Not Found   \n",
       "2    IT Security jaringan | Menguasai perangkat sec...  Not Found   \n",
       "3    Business Collaboration: Partner with business ...  Not Found   \n",
       "4    As a Security Architect - Create and enhance s...  Not Found   \n",
       "..                                                 ...        ...   \n",
       "235  Perform regular penetration testing, vulnerabi...  Not Found   \n",
       "236  Provide expertise to help improve security dom...  Not Found   \n",
       "237  Monitor security systems and tools to detect a...  Not Found   \n",
       "238  In periodically and ad hoc basis, carry out th...  Not Found   \n",
       "239  Drive strategic business value and innovation....  Not Found   \n",
       "\n",
       "                                                  Link  \n",
       "0    https://id.linkedin.com/jobs/view/cybersecurit...  \n",
       "1    https://id.linkedin.com/jobs/view/corporate-se...  \n",
       "2    https://id.linkedin.com/jobs/view/it-security-...  \n",
       "3    https://id.linkedin.com/jobs/view/information-...  \n",
       "4    https://id.linkedin.com/jobs/view/it-security-...  \n",
       "..                                                 ...  \n",
       "235  https://id.linkedin.com/jobs/view/penetration-...  \n",
       "236  https://id.linkedin.com/jobs/view/security-ope...  \n",
       "237  https://id.linkedin.com/jobs/view/it-security-...  \n",
       "238  https://id.linkedin.com/jobs/view/cyber-securi...  \n",
       "239  https://id.linkedin.com/jobs/view/head-of-info...  \n",
       "\n",
       "[240 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6 = pd.DataFrame({\n",
    "    \"Title\": titles,\n",
    "    \"Company\": company_name,\n",
    "    \"Location\": locations,\n",
    "    \"Country\": countries,\n",
    "    \"Job Description\": job_description,\n",
    "    \"Job Requirements\": job_requirement,\n",
    "    \"Work Type\" : work_types,\n",
    "    \"Link\": links\n",
    "})\n",
    "\n",
    "df6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0460bb7",
   "metadata": {
    "papermill": {
     "duration": 0.007759,
     "end_time": "2025-05-22T07:52:59.992416",
     "exception": false,
     "start_time": "2025-05-22T07:52:59.984657",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Quality Assurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5eecb422",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T07:53:00.008233Z",
     "iopub.status.busy": "2025-05-22T07:53:00.008010Z",
     "iopub.status.idle": "2025-05-22T07:53:00.011049Z",
     "shell.execute_reply": "2025-05-22T07:53:00.010424Z"
    },
    "papermill": {
     "duration": 0.012071,
     "end_time": "2025-05-22T07:53:00.012049",
     "exception": false,
     "start_time": "2025-05-22T07:52:59.999978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "url_qa = \"https://www.linkedin.com/jobs/search/?currentJobId=4223685654&geoId=102478259&keywords=quality%20assurance&refresh=true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64018e4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T07:53:00.028321Z",
     "iopub.status.busy": "2025-05-22T07:53:00.028105Z",
     "iopub.status.idle": "2025-05-22T07:59:45.537904Z",
     "shell.execute_reply": "2025-05-22T07:59:45.537059Z"
    },
    "papermill": {
     "duration": 405.519978,
     "end_time": "2025-05-22T07:59:45.539682",
     "exception": false,
     "start_time": "2025-05-22T07:53:00.019704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "locations = []\n",
    "titles = []\n",
    "countries = []    \n",
    "links = []\n",
    "company_name = []\n",
    "job_description = []\n",
    "job_requirement = []\n",
    "work_types = []\n",
    "\n",
    "for i in range(0, 100, 25):\n",
    "    url = url_qa + \"&start=\" + str(i)\n",
    "    request = requests.get(url)\n",
    "    soup = BeautifulSoup(request.text, 'html.parser')\n",
    "\n",
    "    # Location\n",
    "    location = soup.findAll(\"span\", {\"class\": \"job-search-card__location\"})\n",
    "    for loc in location:\n",
    "        locations.append(loc.text.replace(\"\\n\", \" \").strip())\n",
    "\n",
    "    # Title\n",
    "    title = soup.findAll(\"h3\", {\"class\": \"base-search-card__title\"})\n",
    "    for t in title:\n",
    "        titles.append(t.text.replace(\"\\n\", \" \").strip())\n",
    "\n",
    "    # Country\n",
    "    for c in location:\n",
    "        countries.append(c.text.replace(\"\\n\", \" \").strip().split(',')[-1])\n",
    "\n",
    "    # Job links\n",
    "    job_links = soup.findAll(\"a\", {\"class\": \"base-card__full-link\"})\n",
    "    for link in job_links:\n",
    "        links.append(link[\"href\"])\n",
    "\n",
    "    # Company names\n",
    "    names = soup.findAll(\"a\", {\"class\": \"hidden-nested-link\"})\n",
    "    for name in names:\n",
    "        company_name.append(name.text.replace(\"\\n\", \" \").strip())\n",
    "\n",
    "# Keywords\n",
    "desc_keywords = ['responsibilities', 'responsibilities:', 'what you’ll do', 'what you will do', 'deskripsi', 'tugas', 'role', 'job description:', 'job description', \n",
    "                 'your main duties in flying with us', 'your impact', \"you’ll get to\"]\n",
    "req_keywords = ['requirement', 'requirement:', 'requirements', 'requirements:', 'qualification', 'qualification:', 'qualifications', 'qualifications:', 'kualifikasi',\n",
    "                'what you’ll need', 'what you will need', 'you should have', 'skills', 'experience', 'job requirements', 'mandatory belongings that you must prepare', \n",
    "                'who we look for', \"you’ll need to succeed\", 'what this role needs', 'kriteria']\n",
    "\n",
    "for link in links:\n",
    "    try:\n",
    "        job_page = requests.get(link)\n",
    "        job_soup = BeautifulSoup(job_page.text, 'html.parser')\n",
    "\n",
    "        # Extract work type\n",
    "        work_type_found = \"Not Found\"\n",
    "        preference_button = job_soup.find(\"button\", class_=\"job-details-preferences-and-skills\")\n",
    "        if preference_button:\n",
    "            pill_divs = preference_button.find_all(\"div\", class_=\"job-details-preferences-and-skills__pill\")\n",
    "            for pill in pill_divs:\n",
    "                span = pill.find(\"span\", class_=\"ui-label ui-label--accent-3 text-body-small\")\n",
    "                if span and span.text.strip() in [\"Remote\", \"On-site\", \"Hybrid\"]:\n",
    "                    work_type_found = span.text.strip()\n",
    "                    break\n",
    "        work_types.append(work_type_found)\n",
    "\n",
    "        # Extract job description & requirements\n",
    "        desc_block = job_soup.find(\"div\", {\"class\": \"show-more-less-html__markup\"})\n",
    "        if desc_block:\n",
    "            items = desc_block.find_all(\"li\")\n",
    "            li_texts = [li.text.strip() for li in items]\n",
    "\n",
    "            desc_part = []\n",
    "            req_part = []\n",
    "\n",
    "            for li_text in li_texts:\n",
    "                text_lower = li_text.lower()\n",
    "                \n",
    "                if any(k in text_lower for k in req_keywords):\n",
    "                    req_part.append(li_text)\n",
    "                elif any(k in text_lower for k in desc_keywords):\n",
    "                    desc_part.append(li_text)\n",
    "                else:\n",
    "                    if any(word in text_lower for word in ['analyze', 'develop', 'manage', 'design', 'plan']):\n",
    "                        desc_part.append(li_text)\n",
    "                    else:\n",
    "                        req_part.append(li_text)\n",
    "\n",
    "            job_description.append(\" | \".join(desc_part) if desc_part else \"Not Found\")\n",
    "            job_requirement.append(\" | \".join(req_part) if req_part else \"Not Found\")\n",
    "        else:\n",
    "            job_description.append(\"Not Found\")\n",
    "            job_requirement.append(\"Not Found\")\n",
    "\n",
    "        time.sleep(1)\n",
    "    except Exception as e:\n",
    "        job_description.append(\"Error: \" + str(e))\n",
    "        job_requirement.append(\"Error: \" + str(e))\n",
    "        work_types.append(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df1df81a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T07:59:45.557222Z",
     "iopub.status.busy": "2025-05-22T07:59:45.556952Z",
     "iopub.status.idle": "2025-05-22T07:59:45.560593Z",
     "shell.execute_reply": "2025-05-22T07:59:45.560042Z"
    },
    "papermill": {
     "duration": 0.013101,
     "end_time": "2025-05-22T07:59:45.561565",
     "exception": false,
     "start_time": "2025-05-22T07:59:45.548464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_len = min(len(titles), len(locations), len(countries), len(links), len(company_name), len(job_description), len(job_requirement))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60087e11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T07:59:45.577727Z",
     "iopub.status.busy": "2025-05-22T07:59:45.577520Z",
     "iopub.status.idle": "2025-05-22T07:59:45.581351Z",
     "shell.execute_reply": "2025-05-22T07:59:45.580655Z"
    },
    "papermill": {
     "duration": 0.013029,
     "end_time": "2025-05-22T07:59:45.582366",
     "exception": false,
     "start_time": "2025-05-22T07:59:45.569337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "titles = titles[:min_len]\n",
    "locations = locations[:min_len]\n",
    "countries = countries[:min_len]\n",
    "links = links[:min_len]\n",
    "company_name = company_name[:min_len]\n",
    "job_description = job_description[:min_len]\n",
    "job_requirement = job_requirement[:min_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae4116be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T07:59:45.598694Z",
     "iopub.status.busy": "2025-05-22T07:59:45.598492Z",
     "iopub.status.idle": "2025-05-22T07:59:45.610209Z",
     "shell.execute_reply": "2025-05-22T07:59:45.609537Z"
    },
    "papermill": {
     "duration": 0.021022,
     "end_time": "2025-05-22T07:59:45.611273",
     "exception": false,
     "start_time": "2025-05-22T07:59:45.590251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Country</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Job Requirements</th>\n",
       "      <th>Work Type</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quality Assurance &amp; Regulatory Staff</td>\n",
       "      <td>Kalbe Nutritionals (PT Sanghiang Perkasa)</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Manage incoming product lab testing to ensure ...</td>\n",
       "      <td>Register all products and checking the status ...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/quality-assu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QA Microbiology Jr. Staff</td>\n",
       "      <td>Kalbe Nutritionals (PT Sanghiang Perkasa)</td>\n",
       "      <td>West Karawang, West Java, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Melakukan analisa sampel patogen dan non patog...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/qa-microbiol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Packaging Development Staff (Maternity Leave)</td>\n",
       "      <td>Kalbe Nutritionals (PT Sanghiang Perkasa)</td>\n",
       "      <td>East Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Memiliki pengalaman bidang Packaging Developme...</td>\n",
       "      <td>Mengetahui basic knowledge tentang teknologi p...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/packaging-de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Development and QA Analyst</td>\n",
       "      <td>PT Astra International Tbk</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Mendukung proses management reporting (analisa...</td>\n",
       "      <td>Melakukan monitoring atas aktivitas administra...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/development-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quality Assurance (Customer Service) - SPX Exp...</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Check Claim Team ticket interactions and ticke...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/quality-assu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>Quality Assurance (QA) ASSA \\tPurwokerto</td>\n",
       "      <td>SIGMATECH</td>\n",
       "      <td>Banyumas, Central Java, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Familiar with Agile software development | Dev...</td>\n",
       "      <td>Experience with testing and performance test a...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/qa-manual-mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>Warehouse - Quality Assurance (QA) - Lampung</td>\n",
       "      <td>Bibit.id</td>\n",
       "      <td>Greater Bandar Lampung</td>\n",
       "      <td>Greater Bandar Lampung</td>\n",
       "      <td>Define and analyze metrics to guide product de...</td>\n",
       "      <td>Understand markets, industry landscapes, and u...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/product-mana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>Quality Assurance Data Analyst</td>\n",
       "      <td>Sea</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Be involved in whole development life cycle an...</td>\n",
       "      <td>Functional testing via grey-box and white-box ...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/qa-engineer-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>Warehouse - Quality Assurance (QA) - Batam</td>\n",
       "      <td>Anteraja</td>\n",
       "      <td>Batam, Riau Islands, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Melakukan pengawasan terhadap proses harian op...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/warehouse-qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>QA Manual (Middle Level) - Banking Industry</td>\n",
       "      <td>Mitra Keluarga</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Memiliki pengetahuan tentang standar akreditas...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/quality-syst...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>236 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "0                 Quality Assurance & Regulatory Staff   \n",
       "1                            QA Microbiology Jr. Staff   \n",
       "2        Packaging Development Staff (Maternity Leave)   \n",
       "3                           Development and QA Analyst   \n",
       "4    Quality Assurance (Customer Service) - SPX Exp...   \n",
       "..                                                 ...   \n",
       "231           Quality Assurance (QA) ASSA \\tPurwokerto   \n",
       "232       Warehouse - Quality Assurance (QA) - Lampung   \n",
       "233                     Quality Assurance Data Analyst   \n",
       "234         Warehouse - Quality Assurance (QA) - Batam   \n",
       "235        QA Manual (Middle Level) - Banking Industry   \n",
       "\n",
       "                                       Company  \\\n",
       "0    Kalbe Nutritionals (PT Sanghiang Perkasa)   \n",
       "1    Kalbe Nutritionals (PT Sanghiang Perkasa)   \n",
       "2    Kalbe Nutritionals (PT Sanghiang Perkasa)   \n",
       "3                   PT Astra International Tbk   \n",
       "4                                       Shopee   \n",
       "..                                         ...   \n",
       "231                                  SIGMATECH   \n",
       "232                                   Bibit.id   \n",
       "233                                        Sea   \n",
       "234                                   Anteraja   \n",
       "235                             Mitra Keluarga   \n",
       "\n",
       "                                Location                 Country  \\\n",
       "0            Jakarta, Jakarta, Indonesia               Indonesia   \n",
       "1    West Karawang, West Java, Indonesia               Indonesia   \n",
       "2       East Jakarta, Jakarta, Indonesia               Indonesia   \n",
       "3            Jakarta, Jakarta, Indonesia               Indonesia   \n",
       "4                     Jakarta, Indonesia               Indonesia   \n",
       "..                                   ...                     ...   \n",
       "231    Banyumas, Central Java, Indonesia               Indonesia   \n",
       "232               Greater Bandar Lampung  Greater Bandar Lampung   \n",
       "233          Jakarta, Jakarta, Indonesia               Indonesia   \n",
       "234       Batam, Riau Islands, Indonesia               Indonesia   \n",
       "235          Jakarta, Jakarta, Indonesia               Indonesia   \n",
       "\n",
       "                                       Job Description  \\\n",
       "0    Manage incoming product lab testing to ensure ...   \n",
       "1                                            Not Found   \n",
       "2    Memiliki pengalaman bidang Packaging Developme...   \n",
       "3    Mendukung proses management reporting (analisa...   \n",
       "4                                            Not Found   \n",
       "..                                                 ...   \n",
       "231  Familiar with Agile software development | Dev...   \n",
       "232  Define and analyze metrics to guide product de...   \n",
       "233  Be involved in whole development life cycle an...   \n",
       "234                                          Not Found   \n",
       "235                                          Not Found   \n",
       "\n",
       "                                      Job Requirements  Work Type  \\\n",
       "0    Register all products and checking the status ...  Not Found   \n",
       "1    Melakukan analisa sampel patogen dan non patog...  Not Found   \n",
       "2    Mengetahui basic knowledge tentang teknologi p...  Not Found   \n",
       "3    Melakukan monitoring atas aktivitas administra...  Not Found   \n",
       "4    Check Claim Team ticket interactions and ticke...  Not Found   \n",
       "..                                                 ...        ...   \n",
       "231  Experience with testing and performance test a...  Not Found   \n",
       "232  Understand markets, industry landscapes, and u...  Not Found   \n",
       "233  Functional testing via grey-box and white-box ...  Not Found   \n",
       "234  Melakukan pengawasan terhadap proses harian op...  Not Found   \n",
       "235  Memiliki pengetahuan tentang standar akreditas...  Not Found   \n",
       "\n",
       "                                                  Link  \n",
       "0    https://id.linkedin.com/jobs/view/quality-assu...  \n",
       "1    https://id.linkedin.com/jobs/view/qa-microbiol...  \n",
       "2    https://id.linkedin.com/jobs/view/packaging-de...  \n",
       "3    https://id.linkedin.com/jobs/view/development-...  \n",
       "4    https://id.linkedin.com/jobs/view/quality-assu...  \n",
       "..                                                 ...  \n",
       "231  https://id.linkedin.com/jobs/view/qa-manual-mi...  \n",
       "232  https://id.linkedin.com/jobs/view/product-mana...  \n",
       "233  https://id.linkedin.com/jobs/view/qa-engineer-...  \n",
       "234  https://id.linkedin.com/jobs/view/warehouse-qu...  \n",
       "235  https://id.linkedin.com/jobs/view/quality-syst...  \n",
       "\n",
       "[236 rows x 8 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7 = pd.DataFrame({\n",
    "    \"Title\": titles,\n",
    "    \"Company\": company_name,\n",
    "    \"Location\": locations,\n",
    "    \"Country\": countries,\n",
    "    \"Job Description\": job_description,\n",
    "    \"Job Requirements\": job_requirement,\n",
    "    \"Work Type\" : work_types,\n",
    "    \"Link\": links\n",
    "})\n",
    "\n",
    "df7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd21f78f",
   "metadata": {
    "papermill": {
     "duration": 0.007809,
     "end_time": "2025-05-22T07:59:45.627282",
     "exception": false,
     "start_time": "2025-05-22T07:59:45.619473",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DevOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39b947c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T07:59:45.643772Z",
     "iopub.status.busy": "2025-05-22T07:59:45.643584Z",
     "iopub.status.idle": "2025-05-22T07:59:45.646567Z",
     "shell.execute_reply": "2025-05-22T07:59:45.645914Z"
    },
    "papermill": {
     "duration": 0.012412,
     "end_time": "2025-05-22T07:59:45.647564",
     "exception": false,
     "start_time": "2025-05-22T07:59:45.635152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "url_devops = \"https://www.linkedin.com/jobs/search/?currentJobId=4218023799&geoId=102478259&keywords=devops&refresh=true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "295e862b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T07:59:45.664457Z",
     "iopub.status.busy": "2025-05-22T07:59:45.664262Z",
     "iopub.status.idle": "2025-05-22T08:06:52.305551Z",
     "shell.execute_reply": "2025-05-22T08:06:52.304715Z"
    },
    "papermill": {
     "duration": 426.651488,
     "end_time": "2025-05-22T08:06:52.307102",
     "exception": false,
     "start_time": "2025-05-22T07:59:45.655614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "locations = []\n",
    "titles = []\n",
    "countries = []    \n",
    "links = []\n",
    "company_name = []\n",
    "job_description = []\n",
    "job_requirement = []\n",
    "work_types = []\n",
    "\n",
    "for i in range(0, 100, 25):\n",
    "    url = url_devops + \"&start=\" + str(i)\n",
    "    request = requests.get(url)\n",
    "    soup = BeautifulSoup(request.text, 'html.parser')\n",
    "\n",
    "    # Location\n",
    "    location = soup.findAll(\"span\", {\"class\": \"job-search-card__location\"})\n",
    "    for loc in location:\n",
    "        locations.append(loc.text.replace(\"\\n\", \" \").strip())\n",
    "\n",
    "    # Title\n",
    "    title = soup.findAll(\"h3\", {\"class\": \"base-search-card__title\"})\n",
    "    for t in title:\n",
    "        titles.append(t.text.replace(\"\\n\", \" \").strip())\n",
    "\n",
    "    # Country\n",
    "    for c in location:\n",
    "        countries.append(c.text.replace(\"\\n\", \" \").strip().split(',')[-1])\n",
    "\n",
    "    # Job links\n",
    "    job_links = soup.findAll(\"a\", {\"class\": \"base-card__full-link\"})\n",
    "    for link in job_links:\n",
    "        links.append(link[\"href\"])\n",
    "\n",
    "    # Company names\n",
    "    names = soup.findAll(\"a\", {\"class\": \"hidden-nested-link\"})\n",
    "    for name in names:\n",
    "        company_name.append(name.text.replace(\"\\n\", \" \").strip())\n",
    "\n",
    "# Keywords\n",
    "desc_keywords = ['responsibilities', 'responsibilities:', 'what you’ll do', 'what you will do', 'deskripsi', 'tugas', 'role', 'job description:', 'job description', \n",
    "                 'your main duties in flying with us', 'your impact', \"you’ll get to\"]\n",
    "req_keywords = ['requirement', 'requirement:', 'requirements', 'requirements:', 'qualification', 'qualification:', 'qualifications', 'qualifications:', 'kualifikasi',\n",
    "                'what you’ll need', 'what you will need', 'you should have', 'skills', 'experience', 'job requirements', 'mandatory belongings that you must prepare', \n",
    "                'who we look for', \"you’ll need to succeed\", 'what this role needs', 'kriteria']\n",
    "\n",
    "for link in links:\n",
    "    try:\n",
    "        job_page = requests.get(link)\n",
    "        job_soup = BeautifulSoup(job_page.text, 'html.parser')\n",
    "\n",
    "        # Extract work type\n",
    "        work_type_found = \"Not Found\"\n",
    "        preference_button = job_soup.find(\"button\", class_=\"job-details-preferences-and-skills\")\n",
    "        if preference_button:\n",
    "            pill_divs = preference_button.find_all(\"div\", class_=\"job-details-preferences-and-skills__pill\")\n",
    "            for pill in pill_divs:\n",
    "                span = pill.find(\"span\", class_=\"ui-label ui-label--accent-3 text-body-small\")\n",
    "                if span and span.text.strip() in [\"Remote\", \"On-site\", \"Hybrid\"]:\n",
    "                    work_type_found = span.text.strip()\n",
    "                    break\n",
    "        work_types.append(work_type_found)\n",
    "\n",
    "        # Extract job description & requirements\n",
    "        desc_block = job_soup.find(\"div\", {\"class\": \"show-more-less-html__markup\"})\n",
    "        if desc_block:\n",
    "            items = desc_block.find_all(\"li\")\n",
    "            li_texts = [li.text.strip() for li in items]\n",
    "\n",
    "            desc_part = []\n",
    "            req_part = []\n",
    "\n",
    "            for li_text in li_texts:\n",
    "                text_lower = li_text.lower()\n",
    "                \n",
    "                if any(k in text_lower for k in req_keywords):\n",
    "                    req_part.append(li_text)\n",
    "                elif any(k in text_lower for k in desc_keywords):\n",
    "                    desc_part.append(li_text)\n",
    "                else:\n",
    "                    if any(word in text_lower for word in ['analyze', 'develop', 'manage', 'design', 'plan']):\n",
    "                        desc_part.append(li_text)\n",
    "                    else:\n",
    "                        req_part.append(li_text)\n",
    "\n",
    "            job_description.append(\" | \".join(desc_part) if desc_part else \"Not Found\")\n",
    "            job_requirement.append(\" | \".join(req_part) if req_part else \"Not Found\")\n",
    "        else:\n",
    "            job_description.append(\"Not Found\")\n",
    "            job_requirement.append(\"Not Found\")\n",
    "\n",
    "        time.sleep(1)\n",
    "    except Exception as e:\n",
    "        job_description.append(\"Error: \" + str(e))\n",
    "        job_requirement.append(\"Error: \" + str(e))\n",
    "        work_types.append(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd54374a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T08:06:52.326506Z",
     "iopub.status.busy": "2025-05-22T08:06:52.326270Z",
     "iopub.status.idle": "2025-05-22T08:06:52.339291Z",
     "shell.execute_reply": "2025-05-22T08:06:52.338527Z"
    },
    "papermill": {
     "duration": 0.023995,
     "end_time": "2025-05-22T08:06:52.340472",
     "exception": false,
     "start_time": "2025-05-22T08:06:52.316477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Country</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Job Requirements</th>\n",
       "      <th>Work Type</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DevOps</td>\n",
       "      <td>PT. RAKHASA ARTHA WISESA</td>\n",
       "      <td>Jakarta Metropolitan Area</td>\n",
       "      <td>Jakarta Metropolitan Area</td>\n",
       "      <td>Pengalaman dalam pemantauan dan log management...</td>\n",
       "      <td>Pendidikan | Minimal lulusan S1 di bidang Ilmu...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/devops-at-pt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Devops</td>\n",
       "      <td>Binar Academy</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Hybrid (sebagian besar di Jabodetabek area) | ...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/devops-at-bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DevSecOps</td>\n",
       "      <td>PT ITSEC Asia Tbk</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Design, implement, and maintain secure CI/CD p...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/devsecops-at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Devops Engineering</td>\n",
       "      <td>bitcorp. (PT. Bringin Inti Teknologi)</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Automate infrastructure management using tools...</td>\n",
       "      <td>Build, maintain, and optimize Continuous Integ...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/devops-engin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr DevOps</td>\n",
       "      <td>Sprout Digital Labs</td>\n",
       "      <td>Kota Tangerang Selatan, Banten, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Building and setting up new development tools ...</td>\n",
       "      <td>Defining/Managing/Monitoring production infras...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/sr-devops-at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Site Reliability Engineer</td>\n",
       "      <td>PT Astra International Tbk</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Menjembatani kesenjangan antara Tim Core Infra...</td>\n",
       "      <td>Menguasai Ketersediaan dan Performa aplikasi d...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/site-reliabi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>DevOps Engineer</td>\n",
       "      <td>Sprint Asia</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Design and implement cluster HCI infrastructur...</td>\n",
       "      <td>Perform corrective and preventive maintenance ...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/devops-engin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Site Reliability Engineer (SRE)</td>\n",
       "      <td>Fazz</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Deploy, automate, maintain, and manage various...</td>\n",
       "      <td>Understanding the high-level overview of our a...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/site-reliabi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>Country Head - Indonesia</td>\n",
       "      <td>Searce Inc</td>\n",
       "      <td>Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Oversee and manage a team of Regional Sales Ma...</td>\n",
       "      <td>An enthusiastic Technology Consulting &amp; Busine...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/country-head...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>Cloud Infrastructure Engineer</td>\n",
       "      <td>DKATALIS</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Oversee end-to-end Platform architecture and r...</td>\n",
       "      <td>Cloud Infra: Google Cloud, Kubernetes, Docker ...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/cloud-infras...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Title                                Company  \\\n",
       "0                             DevOps               PT. RAKHASA ARTHA WISESA   \n",
       "1                             Devops                          Binar Academy   \n",
       "2                          DevSecOps                      PT ITSEC Asia Tbk   \n",
       "3                 Devops Engineering  bitcorp. (PT. Bringin Inti Teknologi)   \n",
       "4                          Sr DevOps                    Sprout Digital Labs   \n",
       "..                               ...                                    ...   \n",
       "235        Site Reliability Engineer             PT Astra International Tbk   \n",
       "236                  DevOps Engineer                            Sprint Asia   \n",
       "237  Site Reliability Engineer (SRE)                                   Fazz   \n",
       "238         Country Head - Indonesia                             Searce Inc   \n",
       "239    Cloud Infrastructure Engineer                               DKATALIS   \n",
       "\n",
       "                                      Location                    Country  \\\n",
       "0                    Jakarta Metropolitan Area  Jakarta Metropolitan Area   \n",
       "1                  Jakarta, Jakarta, Indonesia                  Indonesia   \n",
       "2                  Jakarta, Jakarta, Indonesia                  Indonesia   \n",
       "3                  Jakarta, Jakarta, Indonesia                  Indonesia   \n",
       "4    Kota Tangerang Selatan, Banten, Indonesia                  Indonesia   \n",
       "..                                         ...                        ...   \n",
       "235                Jakarta, Jakarta, Indonesia                  Indonesia   \n",
       "236                Jakarta, Jakarta, Indonesia                  Indonesia   \n",
       "237                Jakarta, Jakarta, Indonesia                  Indonesia   \n",
       "238                         Jakarta, Indonesia                  Indonesia   \n",
       "239                Jakarta, Jakarta, Indonesia                  Indonesia   \n",
       "\n",
       "                                       Job Description  \\\n",
       "0    Pengalaman dalam pemantauan dan log management...   \n",
       "1                                            Not Found   \n",
       "2    Design, implement, and maintain secure CI/CD p...   \n",
       "3    Automate infrastructure management using tools...   \n",
       "4    Building and setting up new development tools ...   \n",
       "..                                                 ...   \n",
       "235  Menjembatani kesenjangan antara Tim Core Infra...   \n",
       "236  Design and implement cluster HCI infrastructur...   \n",
       "237  Deploy, automate, maintain, and manage various...   \n",
       "238  Oversee and manage a team of Regional Sales Ma...   \n",
       "239  Oversee end-to-end Platform architecture and r...   \n",
       "\n",
       "                                      Job Requirements  Work Type  \\\n",
       "0    Pendidikan | Minimal lulusan S1 di bidang Ilmu...  Not Found   \n",
       "1    Hybrid (sebagian besar di Jabodetabek area) | ...  Not Found   \n",
       "2                                            Not Found  Not Found   \n",
       "3    Build, maintain, and optimize Continuous Integ...  Not Found   \n",
       "4    Defining/Managing/Monitoring production infras...  Not Found   \n",
       "..                                                 ...        ...   \n",
       "235  Menguasai Ketersediaan dan Performa aplikasi d...  Not Found   \n",
       "236  Perform corrective and preventive maintenance ...  Not Found   \n",
       "237  Understanding the high-level overview of our a...  Not Found   \n",
       "238  An enthusiastic Technology Consulting & Busine...  Not Found   \n",
       "239  Cloud Infra: Google Cloud, Kubernetes, Docker ...  Not Found   \n",
       "\n",
       "                                                  Link  \n",
       "0    https://id.linkedin.com/jobs/view/devops-at-pt...  \n",
       "1    https://id.linkedin.com/jobs/view/devops-at-bi...  \n",
       "2    https://id.linkedin.com/jobs/view/devsecops-at...  \n",
       "3    https://id.linkedin.com/jobs/view/devops-engin...  \n",
       "4    https://id.linkedin.com/jobs/view/sr-devops-at...  \n",
       "..                                                 ...  \n",
       "235  https://id.linkedin.com/jobs/view/site-reliabi...  \n",
       "236  https://id.linkedin.com/jobs/view/devops-engin...  \n",
       "237  https://id.linkedin.com/jobs/view/site-reliabi...  \n",
       "238  https://id.linkedin.com/jobs/view/country-head...  \n",
       "239  https://id.linkedin.com/jobs/view/cloud-infras...  \n",
       "\n",
       "[240 rows x 8 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8 = pd.DataFrame({\n",
    "    \"Title\": titles,\n",
    "    \"Company\": company_name,\n",
    "    \"Location\": locations,\n",
    "    \"Country\": countries,\n",
    "    \"Job Description\": job_description,\n",
    "    \"Job Requirements\": job_requirement,\n",
    "    \"Work Type\" : work_types,\n",
    "    \"Link\": links\n",
    "})\n",
    "\n",
    "df8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f338639e",
   "metadata": {
    "papermill": {
     "duration": 0.008849,
     "end_time": "2025-05-22T08:06:52.358876",
     "exception": false,
     "start_time": "2025-05-22T08:06:52.350027",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c8a6875",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T08:06:52.377887Z",
     "iopub.status.busy": "2025-05-22T08:06:52.377311Z",
     "iopub.status.idle": "2025-05-22T08:06:52.380426Z",
     "shell.execute_reply": "2025-05-22T08:06:52.379889Z"
    },
    "papermill": {
     "duration": 0.013927,
     "end_time": "2025-05-22T08:06:52.381614",
     "exception": false,
     "start_time": "2025-05-22T08:06:52.367687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "url_writer = 'https://www.linkedin.com/jobs/search/?currentJobId=4219587624&geoId=102478259&keywords=writer&refresh=true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0867fd4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T08:06:52.400277Z",
     "iopub.status.busy": "2025-05-22T08:06:52.400056Z",
     "iopub.status.idle": "2025-05-22T08:12:07.337204Z",
     "shell.execute_reply": "2025-05-22T08:12:07.336634Z"
    },
    "papermill": {
     "duration": 314.94811,
     "end_time": "2025-05-22T08:12:07.338702",
     "exception": false,
     "start_time": "2025-05-22T08:06:52.390592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "locations = []\n",
    "titles = []\n",
    "countries = []    \n",
    "links = []\n",
    "company_name = []\n",
    "job_description = []\n",
    "job_requirement = []\n",
    "work_types = []\n",
    "\n",
    "for i in range(0, 100, 25):\n",
    "    url = url_writer + \"&start=\" + str(i)\n",
    "    request = requests.get(url)\n",
    "    soup = BeautifulSoup(request.text, 'html.parser')\n",
    "\n",
    "    # Location\n",
    "    location = soup.findAll(\"span\", {\"class\": \"job-search-card__location\"})\n",
    "    for loc in location:\n",
    "        locations.append(loc.text.replace(\"\\n\", \" \").strip())\n",
    "\n",
    "    # Title\n",
    "    title = soup.findAll(\"h3\", {\"class\": \"base-search-card__title\"})\n",
    "    for t in title:\n",
    "        titles.append(t.text.replace(\"\\n\", \" \").strip())\n",
    "\n",
    "    # Country\n",
    "    for c in location:\n",
    "        countries.append(c.text.replace(\"\\n\", \" \").strip().split(',')[-1])\n",
    "\n",
    "    # Job links\n",
    "    job_links = soup.findAll(\"a\", {\"class\": \"base-card__full-link\"})\n",
    "    for link in job_links:\n",
    "        links.append(link[\"href\"])\n",
    "\n",
    "    # Company names\n",
    "    names = soup.findAll(\"a\", {\"class\": \"hidden-nested-link\"})\n",
    "    for name in names:\n",
    "        company_name.append(name.text.replace(\"\\n\", \" \").strip())\n",
    "\n",
    "# Keywords\n",
    "desc_keywords = ['responsibilities', 'responsibilities:', 'what you’ll do', 'what you will do', 'deskripsi', 'tugas', 'role', 'job description:', 'job description', \n",
    "                 'your main duties in flying with us', 'your impact', \"you’ll get to\"]\n",
    "req_keywords = ['requirement', 'requirement:', 'requirements', 'requirements:', 'qualification', 'qualification:', 'qualifications', 'qualifications:', 'kualifikasi',\n",
    "                'what you’ll need', 'what you will need', 'you should have', 'skills', 'experience', 'job requirements', 'mandatory belongings that you must prepare', \n",
    "                'who we look for', \"you’ll need to succeed\", 'what this role needs', 'kriteria']\n",
    "\n",
    "for link in links:\n",
    "    try:\n",
    "        job_page = requests.get(link)\n",
    "        job_soup = BeautifulSoup(job_page.text, 'html.parser')\n",
    "\n",
    "        # Extract work type\n",
    "        work_type_found = \"Not Found\"\n",
    "        preference_button = job_soup.find(\"button\", class_=\"job-details-preferences-and-skills\")\n",
    "        if preference_button:\n",
    "            pill_divs = preference_button.find_all(\"div\", class_=\"job-details-preferences-and-skills__pill\")\n",
    "            for pill in pill_divs:\n",
    "                span = pill.find(\"span\", class_=\"ui-label ui-label--accent-3 text-body-small\")\n",
    "                if span and span.text.strip() in [\"Remote\", \"On-site\", \"Hybrid\"]:\n",
    "                    work_type_found = span.text.strip()\n",
    "                    break\n",
    "        work_types.append(work_type_found)\n",
    "\n",
    "        # Extract job description & requirements\n",
    "        desc_block = job_soup.find(\"div\", {\"class\": \"show-more-less-html__markup\"})\n",
    "        if desc_block:\n",
    "            items = desc_block.find_all(\"li\")\n",
    "            li_texts = [li.text.strip() for li in items]\n",
    "\n",
    "            desc_part = []\n",
    "            req_part = []\n",
    "\n",
    "            for li_text in li_texts:\n",
    "                text_lower = li_text.lower()\n",
    "                \n",
    "                if any(k in text_lower for k in req_keywords):\n",
    "                    req_part.append(li_text)\n",
    "                elif any(k in text_lower for k in desc_keywords):\n",
    "                    desc_part.append(li_text)\n",
    "                else:\n",
    "                    if any(word in text_lower for word in ['analyze', 'develop', 'manage', 'design', 'plan']):\n",
    "                        desc_part.append(li_text)\n",
    "                    else:\n",
    "                        req_part.append(li_text)\n",
    "\n",
    "            job_description.append(\" | \".join(desc_part) if desc_part else \"Not Found\")\n",
    "            job_requirement.append(\" | \".join(req_part) if req_part else \"Not Found\")\n",
    "        else:\n",
    "            job_description.append(\"Not Found\")\n",
    "            job_requirement.append(\"Not Found\")\n",
    "\n",
    "        time.sleep(1)\n",
    "    except Exception as e:\n",
    "        job_description.append(\"Error: \" + str(e))\n",
    "        job_requirement.append(\"Error: \" + str(e))\n",
    "        work_types.append(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df969b9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T08:12:07.357784Z",
     "iopub.status.busy": "2025-05-22T08:12:07.357571Z",
     "iopub.status.idle": "2025-05-22T08:12:07.369437Z",
     "shell.execute_reply": "2025-05-22T08:12:07.368799Z"
    },
    "papermill": {
     "duration": 0.022455,
     "end_time": "2025-05-22T08:12:07.370609",
     "exception": false,
     "start_time": "2025-05-22T08:12:07.348154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Country</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Job Requirements</th>\n",
       "      <th>Work Type</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Creative Copywriter Internship</td>\n",
       "      <td>PT Bank Sinarmas Tbk</td>\n",
       "      <td>Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/creative-cop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Freelance Proofreader</td>\n",
       "      <td>Firstsource</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Competitive pay (up to ₹1000/hour). | Flexible...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/freelance-pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Penulis Lepas Bahasa Indonesia</td>\n",
       "      <td>Outlier</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Membaca teks berbahasa Indonesia untuk memberi...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/penulis-lepa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Copywriter - Contract-based</td>\n",
       "      <td>PT Astra International Tbk</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Menulis teks iklan yang menarik dan persuasif ...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/copywriter-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Copywriter</td>\n",
       "      <td>dentsu</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Collaborative team player, working effectively...</td>\n",
       "      <td>Write narratives, scripts, storyboards, annota...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/copywriter-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Sosial Media Project, Script Writer Freelance ...</td>\n",
       "      <td>State University of Malang</td>\n",
       "      <td>Malang, East Java, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/sosial-media...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Copywriter</td>\n",
       "      <td>RiDiK (a Subsidiary of CLPS. Nasdaq: CLPS)</td>\n",
       "      <td>Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Develop captions, short stories, and copy that...</td>\n",
       "      <td>Write captivating content for social media pla...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/copywriter-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Technical Writer</td>\n",
       "      <td>PT. Metrodata Electronics Tbk.</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Write easy-to-understand user interface text, ...</td>\n",
       "      <td>Work with internal teams to obtain an in-depth...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/technical-wr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Suomenkielinen freelance-kirjoittaja</td>\n",
       "      <td>Outlier</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Suomenkielisten tekstien lukeminen ja tekoälym...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/suomenkielin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Hindi Freelance Writer</td>\n",
       "      <td>Outlier</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Outlier is looking for talented writers with f...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/hindi-freela...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "0                       Creative Copywriter Internship   \n",
       "1                                Freelance Proofreader   \n",
       "2                       Penulis Lepas Bahasa Indonesia   \n",
       "3                          Copywriter - Contract-based   \n",
       "4                                           Copywriter   \n",
       "..                                                 ...   \n",
       "175  Sosial Media Project, Script Writer Freelance ...   \n",
       "176                                         Copywriter   \n",
       "177                                   Technical Writer   \n",
       "178               Suomenkielinen freelance-kirjoittaja   \n",
       "179                             Hindi Freelance Writer   \n",
       "\n",
       "                                        Company                      Location  \\\n",
       "0                          PT Bank Sinarmas Tbk            Jakarta, Indonesia   \n",
       "1                                   Firstsource                     Indonesia   \n",
       "2                                       Outlier                     Indonesia   \n",
       "3                    PT Astra International Tbk   Jakarta, Jakarta, Indonesia   \n",
       "4                                        dentsu   Jakarta, Jakarta, Indonesia   \n",
       "..                                          ...                           ...   \n",
       "175                  State University of Malang  Malang, East Java, Indonesia   \n",
       "176  RiDiK (a Subsidiary of CLPS. Nasdaq: CLPS)            Jakarta, Indonesia   \n",
       "177              PT. Metrodata Electronics Tbk.   Jakarta, Jakarta, Indonesia   \n",
       "178                                     Outlier                     Indonesia   \n",
       "179                                     Outlier                     Indonesia   \n",
       "\n",
       "        Country                                    Job Description  \\\n",
       "0     Indonesia                                          Not Found   \n",
       "1     Indonesia                                          Not Found   \n",
       "2     Indonesia                                          Not Found   \n",
       "3     Indonesia                                          Not Found   \n",
       "4     Indonesia  Collaborative team player, working effectively...   \n",
       "..          ...                                                ...   \n",
       "175   Indonesia                                          Not Found   \n",
       "176   Indonesia  Develop captions, short stories, and copy that...   \n",
       "177   Indonesia  Write easy-to-understand user interface text, ...   \n",
       "178   Indonesia                                          Not Found   \n",
       "179   Indonesia                                          Not Found   \n",
       "\n",
       "                                      Job Requirements  Work Type  \\\n",
       "0                                            Not Found  Not Found   \n",
       "1    Competitive pay (up to ₹1000/hour). | Flexible...  Not Found   \n",
       "2    Membaca teks berbahasa Indonesia untuk memberi...  Not Found   \n",
       "3    Menulis teks iklan yang menarik dan persuasif ...  Not Found   \n",
       "4    Write narratives, scripts, storyboards, annota...  Not Found   \n",
       "..                                                 ...        ...   \n",
       "175                                          Not Found  Not Found   \n",
       "176  Write captivating content for social media pla...  Not Found   \n",
       "177  Work with internal teams to obtain an in-depth...  Not Found   \n",
       "178  Suomenkielisten tekstien lukeminen ja tekoälym...  Not Found   \n",
       "179  Outlier is looking for talented writers with f...  Not Found   \n",
       "\n",
       "                                                  Link  \n",
       "0    https://id.linkedin.com/jobs/view/creative-cop...  \n",
       "1    https://id.linkedin.com/jobs/view/freelance-pr...  \n",
       "2    https://id.linkedin.com/jobs/view/penulis-lepa...  \n",
       "3    https://id.linkedin.com/jobs/view/copywriter-c...  \n",
       "4    https://id.linkedin.com/jobs/view/copywriter-a...  \n",
       "..                                                 ...  \n",
       "175  https://id.linkedin.com/jobs/view/sosial-media...  \n",
       "176  https://id.linkedin.com/jobs/view/copywriter-a...  \n",
       "177  https://id.linkedin.com/jobs/view/technical-wr...  \n",
       "178  https://id.linkedin.com/jobs/view/suomenkielin...  \n",
       "179  https://id.linkedin.com/jobs/view/hindi-freela...  \n",
       "\n",
       "[180 rows x 8 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df9 = pd.DataFrame({\n",
    "    \"Title\": titles,\n",
    "    \"Company\": company_name,\n",
    "    \"Location\": locations,\n",
    "    \"Country\": countries,\n",
    "    \"Job Description\": job_description,\n",
    "    \"Job Requirements\": job_requirement,\n",
    "    \"Work Type\" : work_types,\n",
    "    \"Link\": links\n",
    "})\n",
    "\n",
    "df9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c7206d",
   "metadata": {
    "papermill": {
     "duration": 0.008682,
     "end_time": "2025-05-22T08:12:07.388628",
     "exception": false,
     "start_time": "2025-05-22T08:12:07.379946",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f85a2cef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T08:12:07.406815Z",
     "iopub.status.busy": "2025-05-22T08:12:07.406483Z",
     "iopub.status.idle": "2025-05-22T08:12:07.409636Z",
     "shell.execute_reply": "2025-05-22T08:12:07.409001Z"
    },
    "papermill": {
     "duration": 0.013437,
     "end_time": "2025-05-22T08:12:07.410620",
     "exception": false,
     "start_time": "2025-05-22T08:12:07.397183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "url_editor = 'https://www.linkedin.com/jobs/search/?currentJobId=4229431159&geoId=102478259&keywords=editor&refresh=true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f05cf2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T08:12:07.428985Z",
     "iopub.status.busy": "2025-05-22T08:12:07.428797Z",
     "iopub.status.idle": "2025-05-22T08:19:13.734003Z",
     "shell.execute_reply": "2025-05-22T08:19:13.733432Z"
    },
    "papermill": {
     "duration": 426.315965,
     "end_time": "2025-05-22T08:19:13.735400",
     "exception": false,
     "start_time": "2025-05-22T08:12:07.419435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "locations = []\n",
    "titles = []\n",
    "countries = []    \n",
    "links = []\n",
    "company_name = []\n",
    "job_description = []\n",
    "job_requirement = []\n",
    "work_types = []\n",
    "\n",
    "for i in range(0, 100, 25):\n",
    "    url = url_editor + \"&start=\" + str(i)\n",
    "    request = requests.get(url)\n",
    "    soup = BeautifulSoup(request.text, 'html.parser')\n",
    "\n",
    "    # Location\n",
    "    location = soup.findAll(\"span\", {\"class\": \"job-search-card__location\"})\n",
    "    for loc in location:\n",
    "        locations.append(loc.text.replace(\"\\n\", \" \").strip())\n",
    "\n",
    "    # Title\n",
    "    title = soup.findAll(\"h3\", {\"class\": \"base-search-card__title\"})\n",
    "    for t in title:\n",
    "        titles.append(t.text.replace(\"\\n\", \" \").strip())\n",
    "\n",
    "    # Country\n",
    "    for c in location:\n",
    "        countries.append(c.text.replace(\"\\n\", \" \").strip().split(',')[-1])\n",
    "\n",
    "    # Job links\n",
    "    job_links = soup.findAll(\"a\", {\"class\": \"base-card__full-link\"})\n",
    "    for link in job_links:\n",
    "        links.append(link[\"href\"])\n",
    "\n",
    "    # Company names\n",
    "    names = soup.findAll(\"a\", {\"class\": \"hidden-nested-link\"})\n",
    "    for name in names:\n",
    "        company_name.append(name.text.replace(\"\\n\", \" \").strip())\n",
    "\n",
    "# Keywords\n",
    "desc_keywords = ['responsibilities', 'responsibilities:', 'what you’ll do', 'what you will do', 'deskripsi', 'tugas', 'role', 'job description:', 'job description', \n",
    "                 'your main duties in flying with us', 'your impact', \"you’ll get to\"]\n",
    "req_keywords = ['requirement', 'requirement:', 'requirements', 'requirements:', 'qualification', 'qualification:', 'qualifications', 'qualifications:', 'kualifikasi',\n",
    "                'what you’ll need', 'what you will need', 'you should have', 'skills', 'experience', 'job requirements', 'mandatory belongings that you must prepare', \n",
    "                'who we look for', \"you’ll need to succeed\", 'what this role needs', 'kriteria']\n",
    "\n",
    "for link in links:\n",
    "    try:\n",
    "        job_page = requests.get(link)\n",
    "        job_soup = BeautifulSoup(job_page.text, 'html.parser')\n",
    "\n",
    "        # Extract work type\n",
    "        work_type_found = \"Not Found\"\n",
    "        preference_button = job_soup.find(\"button\", class_=\"job-details-preferences-and-skills\")\n",
    "        if preference_button:\n",
    "            pill_divs = preference_button.find_all(\"div\", class_=\"job-details-preferences-and-skills__pill\")\n",
    "            for pill in pill_divs:\n",
    "                span = pill.find(\"span\", class_=\"ui-label ui-label--accent-3 text-body-small\")\n",
    "                if span and span.text.strip() in [\"Remote\", \"On-site\", \"Hybrid\"]:\n",
    "                    work_type_found = span.text.strip()\n",
    "                    break\n",
    "        work_types.append(work_type_found)\n",
    "\n",
    "        # Extract job description & requirements\n",
    "        desc_block = job_soup.find(\"div\", {\"class\": \"show-more-less-html__markup\"})\n",
    "        if desc_block:\n",
    "            items = desc_block.find_all(\"li\")\n",
    "            li_texts = [li.text.strip() for li in items]\n",
    "\n",
    "            desc_part = []\n",
    "            req_part = []\n",
    "\n",
    "            for li_text in li_texts:\n",
    "                text_lower = li_text.lower()\n",
    "                \n",
    "                if any(k in text_lower for k in req_keywords):\n",
    "                    req_part.append(li_text)\n",
    "                elif any(k in text_lower for k in desc_keywords):\n",
    "                    desc_part.append(li_text)\n",
    "                else:\n",
    "                    if any(word in text_lower for word in ['analyze', 'develop', 'manage', 'design', 'plan']):\n",
    "                        desc_part.append(li_text)\n",
    "                    else:\n",
    "                        req_part.append(li_text)\n",
    "\n",
    "            job_description.append(\" | \".join(desc_part) if desc_part else \"Not Found\")\n",
    "            job_requirement.append(\" | \".join(req_part) if req_part else \"Not Found\")\n",
    "        else:\n",
    "            job_description.append(\"Not Found\")\n",
    "            job_requirement.append(\"Not Found\")\n",
    "\n",
    "        time.sleep(1)\n",
    "    except Exception as e:\n",
    "        job_description.append(\"Error: \" + str(e))\n",
    "        job_requirement.append(\"Error: \" + str(e))\n",
    "        work_types.append(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "134d129c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T08:19:13.755131Z",
     "iopub.status.busy": "2025-05-22T08:19:13.754605Z",
     "iopub.status.idle": "2025-05-22T08:19:13.766028Z",
     "shell.execute_reply": "2025-05-22T08:19:13.765509Z"
    },
    "papermill": {
     "duration": 0.022014,
     "end_time": "2025-05-22T08:19:13.767089",
     "exception": false,
     "start_time": "2025-05-22T08:19:13.745075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Country</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Job Requirements</th>\n",
       "      <th>Work Type</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Penulis Lepas Bahasa Indonesia</td>\n",
       "      <td>Outlier</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Membaca teks berbahasa Indonesia untuk memberi...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/penulis-lepa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Freelance Proofreader</td>\n",
       "      <td>Firstsource</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Competitive pay (up to ₹1000/hour). | Flexible...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/freelance-pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Editor Konten Bilingual</td>\n",
       "      <td>DataAnnotation</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/editor-konte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arabic (Saudi) Freelance Writer</td>\n",
       "      <td>Outlier</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Outlier is looking for talented writers with f...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/arabic-saudi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scrittore freelance italiano</td>\n",
       "      <td>Outlier</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Leggendo testi in italiano per classificare un...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/scrittore-fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Photo Editor - Holiday Shift</td>\n",
       "      <td>Pippeline</td>\n",
       "      <td>Kebon Jeruk, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Editor menjadi bagian tim image editing, yang ...</td>\n",
       "      <td>Memiliki pola pikir berkembang atau Growth Min...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/photo-editor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Video Editor</td>\n",
       "      <td>Soulshine Bali</td>\n",
       "      <td>Gianyar, Bali, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Having minimum 2-year experience in the same f...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/video-editor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Content Writer</td>\n",
       "      <td>cmlabs</td>\n",
       "      <td>Malang, East Java, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Job Description | An understanding of how cont...</td>\n",
       "      <td>Company Description | Qualification | Skills |...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/content-writ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>Content Writer</td>\n",
       "      <td>cmlabs</td>\n",
       "      <td>Malang, East Java, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Job Description | An understanding of how cont...</td>\n",
       "      <td>Company Description | Qualification | Skills |...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/content-writ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>Content Writer</td>\n",
       "      <td>cmlabs</td>\n",
       "      <td>Malang, East Java, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Job Description | An understanding of how cont...</td>\n",
       "      <td>Company Description | Qualification | Skills |...</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/content-writ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Title         Company  \\\n",
       "0     Penulis Lepas Bahasa Indonesia         Outlier   \n",
       "1              Freelance Proofreader     Firstsource   \n",
       "2            Editor Konten Bilingual  DataAnnotation   \n",
       "3    Arabic (Saudi) Freelance Writer         Outlier   \n",
       "4       Scrittore freelance italiano         Outlier   \n",
       "..                               ...             ...   \n",
       "235     Photo Editor - Holiday Shift       Pippeline   \n",
       "236                     Video Editor  Soulshine Bali   \n",
       "237                   Content Writer          cmlabs   \n",
       "238                   Content Writer          cmlabs   \n",
       "239                   Content Writer          cmlabs   \n",
       "\n",
       "                            Location     Country  \\\n",
       "0                          Indonesia   Indonesia   \n",
       "1                          Indonesia   Indonesia   \n",
       "2                          Indonesia   Indonesia   \n",
       "3                          Indonesia   Indonesia   \n",
       "4                          Indonesia   Indonesia   \n",
       "..                               ...         ...   \n",
       "235  Kebon Jeruk, Jakarta, Indonesia   Indonesia   \n",
       "236         Gianyar, Bali, Indonesia   Indonesia   \n",
       "237     Malang, East Java, Indonesia   Indonesia   \n",
       "238     Malang, East Java, Indonesia   Indonesia   \n",
       "239     Malang, East Java, Indonesia   Indonesia   \n",
       "\n",
       "                                       Job Description  \\\n",
       "0                                            Not Found   \n",
       "1                                            Not Found   \n",
       "2                                            Not Found   \n",
       "3                                            Not Found   \n",
       "4                                            Not Found   \n",
       "..                                                 ...   \n",
       "235  Editor menjadi bagian tim image editing, yang ...   \n",
       "236                                          Not Found   \n",
       "237  Job Description | An understanding of how cont...   \n",
       "238  Job Description | An understanding of how cont...   \n",
       "239  Job Description | An understanding of how cont...   \n",
       "\n",
       "                                      Job Requirements  Work Type  \\\n",
       "0    Membaca teks berbahasa Indonesia untuk memberi...  Not Found   \n",
       "1    Competitive pay (up to ₹1000/hour). | Flexible...  Not Found   \n",
       "2                                            Not Found  Not Found   \n",
       "3    Outlier is looking for talented writers with f...  Not Found   \n",
       "4    Leggendo testi in italiano per classificare un...  Not Found   \n",
       "..                                                 ...        ...   \n",
       "235  Memiliki pola pikir berkembang atau Growth Min...  Not Found   \n",
       "236  Having minimum 2-year experience in the same f...  Not Found   \n",
       "237  Company Description | Qualification | Skills |...  Not Found   \n",
       "238  Company Description | Qualification | Skills |...  Not Found   \n",
       "239  Company Description | Qualification | Skills |...  Not Found   \n",
       "\n",
       "                                                  Link  \n",
       "0    https://id.linkedin.com/jobs/view/penulis-lepa...  \n",
       "1    https://id.linkedin.com/jobs/view/freelance-pr...  \n",
       "2    https://id.linkedin.com/jobs/view/editor-konte...  \n",
       "3    https://id.linkedin.com/jobs/view/arabic-saudi...  \n",
       "4    https://id.linkedin.com/jobs/view/scrittore-fr...  \n",
       "..                                                 ...  \n",
       "235  https://id.linkedin.com/jobs/view/photo-editor...  \n",
       "236  https://id.linkedin.com/jobs/view/video-editor...  \n",
       "237  https://id.linkedin.com/jobs/view/content-writ...  \n",
       "238  https://id.linkedin.com/jobs/view/content-writ...  \n",
       "239  https://id.linkedin.com/jobs/view/content-writ...  \n",
       "\n",
       "[240 rows x 8 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df10 = pd.DataFrame({\n",
    "    \"Title\": titles,\n",
    "    \"Company\": company_name,\n",
    "    \"Location\": locations,\n",
    "    \"Country\": countries,\n",
    "    \"Job Description\": job_description,\n",
    "    \"Job Requirements\": job_requirement,\n",
    "    \"Work Type\" : work_types,\n",
    "    \"Link\": links\n",
    "})\n",
    "\n",
    "df10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692b30a8",
   "metadata": {
    "papermill": {
     "duration": 0.00893,
     "end_time": "2025-05-22T08:19:13.857082",
     "exception": false,
     "start_time": "2025-05-22T08:19:13.848152",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Combine all df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539b4ce2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T08:19:13.876336Z",
     "iopub.status.busy": "2025-05-22T08:19:13.876099Z",
     "iopub.status.idle": "2025-05-22T08:19:13.995774Z",
     "shell.execute_reply": "2025-05-22T08:19:13.995273Z"
    },
    "papermill": {
     "duration": 0.130411,
     "end_time": "2025-05-22T08:19:13.996978",
     "exception": false,
     "start_time": "2025-05-22T08:19:13.866567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Gabungkan semua DataFrame\n",
    "combined_df = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9, df10], ignore_index=True)\n",
    "\n",
    "# Simpan ke file CSV\n",
    "combined_df.to_csv(\"jobs_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941b44ec",
   "metadata": {},
   "source": [
    "## **Chapter 2: Scrapping Non IT Jobs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae89ba0d",
   "metadata": {},
   "source": [
    "### Fungsi Utama untuk Scraping\n",
    "\n",
    "Fungsi `scrape_linkedin_jobs` ini akan menjadi mesin utama kita. Fungsi ini hanya perlu didefinisikan satu kali dan bisa dipanggil berulang kali untuk setiap kata kunci pekerjaan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b16e0a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_linkedin_jobs(category_url, category_name, max_pages=4):\n",
    "    \"\"\"\n",
    "    Fungsi ini melakukan scraping lowongan pekerjaan dari LinkedIn untuk URL dan nama kategori tertentu.\n",
    "    - category_url: URL pencarian dasar untuk sebuah kategori pekerjaan.\n",
    "    - category_name: Nama kategori (untuk logging/pemberitahuan).\n",
    "    - max_pages: Jumlah halaman yang akan di-scrape (1 halaman = 25 lowongan).\n",
    "    \"\"\"\n",
    "    print(f\"--- Memulai scraping untuk kategori: '{category_name}' ---\")\n",
    "    \n",
    "    # Inisialisasi list untuk menampung data\n",
    "    locations, titles, countries, links, company_name = [], [], [], [], []\n",
    "    job_description, job_requirement, work_types = [], [], []\n",
    "    all_job_links = []\n",
    "\n",
    "    # === BAGIAN A: Mengumpulkan semua link pekerjaan dari halaman pencarian ===\n",
    "    page_range = range(0, max_pages * 25, 25)\n",
    "    for i in page_range:\n",
    "        url = category_url + \"&start=\" + str(i)\n",
    "        try:\n",
    "            request = requests.get(url)\n",
    "            request.raise_for_status()\n",
    "            soup = BeautifulSoup(request.text, 'html.parser')\n",
    "            \n",
    "            print(f\"  Mengambil link dari halaman {i//25 + 1}/{max_pages}...\")\n",
    "            \n",
    "            page_job_links = soup.findAll(\"a\", {\"class\": \"base-card__full-link\"})\n",
    "            for link in page_job_links:\n",
    "                href = link.get(\"href\", \"\")\n",
    "                if href and href not in all_job_links:\n",
    "                    all_job_links.append(href)\n",
    "            \n",
    "            time.sleep(2)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"  Gagal mengambil halaman {url}. Error: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"Total {len(all_job_links)} link pekerjaan unik ditemukan. Memulai scraping detail...\")\n",
    "\n",
    "    # === BAGIAN B: Mengunjungi setiap link untuk mendapatkan detail ===\n",
    "    for idx, link in enumerate(all_job_links):\n",
    "        print(f\"  -> Mengambil detail dari link {idx+1}/{len(all_job_links)}...\", end='\\r')\n",
    "        try:\n",
    "            job_page = requests.get(link)\n",
    "            job_page.raise_for_status()\n",
    "            job_soup = BeautifulSoup(job_page.text, 'html.parser')\n",
    "            \n",
    "            # Ekstraksi data utama\n",
    "            title_tag = job_soup.find(\"h1\", {\"class\": \"top-card-layout__title\"})\n",
    "            company_tag = job_soup.find(\"a\", {\"class\": \"topcard__org-name-link\"})\n",
    "            location_tag = job_soup.find(\"span\", {\"class\": \"topcard__flavor--bullet\"})\n",
    "\n",
    "            titles.append(title_tag.text.strip() if title_tag else \"Not Found\")\n",
    "            company_name.append(company_tag.text.strip() if company_tag else \"Not Found\")\n",
    "            current_location = location_tag.text.strip() if location_tag else \"Not Found\"\n",
    "            locations.append(current_location)\n",
    "            countries.append(current_location.split(',')[-1].strip())\n",
    "            links.append(link)\n",
    "            \n",
    "            # Ekstraksi Work Type\n",
    "            work_type_found = \"Not Found\"\n",
    "            if \"remote\" in current_location.lower(): work_type_found = \"Remote\"\n",
    "            elif \"hybrid\" in current_location.lower(): work_type_found = \"Hybrid\"\n",
    "            else: work_type_found = \"On-site\"\n",
    "            work_types.append(work_type_found)\n",
    "\n",
    "            # Ekstraksi Deskripsi & Requirement\n",
    "            desc_block = job_soup.find(\"div\", {\"class\": \"show-more-less-html__markup\"})\n",
    "            if desc_block:\n",
    "                items = desc_block.find_all([\"p\", \"li\"])\n",
    "                all_text = [item.get_text(strip=True) for item in items]\n",
    "                job_description.append(\" | \".join(all_text) if all_text else \"Not Found\")\n",
    "                job_requirement.append(\"Not Found\") # Kita gabungkan saja semua ke deskripsi untuk simplisitas\n",
    "            else:\n",
    "                job_description.append(\"Not Found\")\n",
    "                job_requirement.append(\"Not Found\")\n",
    "\n",
    "            time.sleep(1)\n",
    "        except Exception as e:\n",
    "            # Jika ada error di satu link, kita skip dan lanjut\n",
    "            continue\n",
    "            \n",
    "    # === BAGIAN C: Membuat DataFrame ===\n",
    "    df = pd.DataFrame({\n",
    "        \"Title\": titles, \"Company\": company_name, \"Location\": locations,\n",
    "        \"Country\": countries, \"Job Description\": job_description,\n",
    "        \"Job Requirements\": job_requirement, \"Work Type\": work_types, \"Link\": links\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n--- Scraping untuk '{category_name}' selesai. Ditemukan {len(df)} pekerjaan. ---\\n\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b007c3",
   "metadata": {},
   "source": [
    "### Definisi Daftar Pekerjaan\n",
    "\n",
    "Di sini kita mendefinisikan semua kata kunci pekerjaan yang ingin di-scrape. Cukup tambahkan atau hapus item dari dictionary `JOBS_TO_SCRAPE` untuk mengontrol pekerjaan apa saja yang akan dicari."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "99a53589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Siap untuk men-scrape 59 jenis pekerjaan.\n"
     ]
    }
   ],
   "source": [
    "# Mencari semua tipe pekerjaan: On-site, Remote, dan Hybrid.\n",
    "BASE_URL = \"https://www.linkedin.com/jobs/search/?geoId=102478259&refresh=true&keywords=\"\n",
    "\n",
    "# Dictionary berisi Nama Kategori dan Kata Kunci URL-nya\n",
    "# Edit daftar ini untuk menambah atau mengurangi pekerjaan\n",
    "JOBS_TO_SCRAPE = {\n",
    "    # IT (sudah cukup baik)\n",
    "    \"Data Analysis\": \"data%20analysis\",\n",
    "    \"Machine Learning\": \"machine%20learning\",\n",
    "    \"Software Tester\": \"software%20tester\",\n",
    "    \"Fullstack Developer\": \"fullstack%20developer\",\n",
    "    \"UI/UX\": \"ui%20ux\",\n",
    "    \"Cybersecurity\": \"cybersecurity\",\n",
    "    \"Quality Assurance\": \"quality%20assurance\",\n",
    "    \"DevOps\": \"devops\",\n",
    "    \"Writer\": \"writer\",\n",
    "    \"Editor\": \"editor\",\n",
    "\n",
    "    # Keuangan & Akuntansi\n",
    "    \"Akuntan (ID)\": \"akuntan\",\n",
    "    \"Accountant (EN)\": \"accountant\",\n",
    "    \"Staf Akuntansi (ID)\": \"staf%20akuntansi\",\n",
    "    \"Accounting Staff (EN)\": \"accounting%20staff\",\n",
    "    \"Manajer Keuangan (ID)\": \"manajer%20keuangan\",\n",
    "    \"Finance Manager (EN)\": \"finance%20manager\",\n",
    "    \"Analis Keuangan (ID)\": \"analis%20keuangan\",\n",
    "    \"Financial Analyst (EN)\": \"financial%20analyst\",\n",
    "    \"Auditor\": \"auditor\",\n",
    "\n",
    "    # Pemasaran & Penjualan\n",
    "    \"Manajer Pemasaran (ID)\": \"manajer%20pemasaran\",\n",
    "    \"Marketing Manager (EN)\": \"marketing%20manager\",\n",
    "    \"Staf Pemasaran (ID)\": \"staf%20pemasaran\",\n",
    "    \"Marketing Staff (EN)\": \"marketing%20staff\",\n",
    "    \"Sales Executive\": \"sales%20executive\",\n",
    "    \"Social Media Specialist\": \"social%20media%20specialist\",\n",
    "    \"Brand Manager\": \"brand%20manager\",\n",
    "    \n",
    "    # Sumber Daya Manusia\n",
    "    \"HRD\": \"hrd\",\n",
    "    \"Human Resources (EN)\": \"human%20resources\",\n",
    "    \"Staf Rekrutmen (ID)\": \"staf%20rekrutmen\",\n",
    "    \"Recruiter (EN)\": \"recruiter\",\n",
    "    \"Payroll\": \"payroll\",\n",
    "    \"Talent Acquisition\": \"talent%20acquisition\",\n",
    "    \n",
    "    # Operasional & Logistik\n",
    "    \"Manajer Operasional (ID)\": \"manajer%20operasional\",\n",
    "    \"Operations Manager (EN)\": \"operations%20manager\",\n",
    "    \"Staf Logistik (ID)\": \"staf%20logistik\",\n",
    "    \"Logistics Staff (EN)\": \"logistics%20staff\",\n",
    "    \"Supply Chain\": \"supply%20chain\",\n",
    "    \"Staf Gudang (ID)\": \"staf%20gudang\",\n",
    "    \"Warehouse Staff (EN)\": \"warehouse%20staff\",\n",
    "    \n",
    "    # Pendidikan\n",
    "    \"Guru\": \"guru\",\n",
    "    \"Dosen (ID)\": \"dosen\",\n",
    "    \"Lecturer (EN)\": \"lecturer\",\n",
    "    \"Konselor Pendidikan (ID)\": \"konselor%20pendidikan\",\n",
    "    \"Education Counselor (EN)\": \"education%20counselor\",\n",
    "    \n",
    "    # Kesehatan\n",
    "    \"Perawat\": \"perawat\",\n",
    "    \"Analis Kesehatan (ID)\": \"analis%20kesehatan\",\n",
    "    \"Health Analyst (EN)\": \"health%20analyst\",\n",
    "    \"Apoteker (ID)\": \"apoteker\",\n",
    "    \"Pharmacist (EN)\": \"pharmacist\",\n",
    "    \n",
    "    # Hukum (Legal)\n",
    "    \"Staf Legal (ID)\": \"staf%20legal\",\n",
    "    \"Legal Staff (EN)\": \"legal%20staff\",\n",
    "    \"Pengacara (ID)\": \"pengacara\",\n",
    "    \"Lawyer (EN)\": \"lawyer\",\n",
    "    \"Corporate Lawyer\": \"corporate%20lawyer\",\n",
    "    \n",
    "    # Hospitality\n",
    "    \"Manajer Hotel (ID)\": \"manajer%20hotel\",\n",
    "    \"Hotel Manager (EN)\": \"hotel%20manager\",\n",
    "    \"Chef\": \"chef\",\n",
    "    \"F&B Service\": \"f%26b%20service\",\n",
    "    \"Front Office\": \"front%20office\"\n",
    "}\n",
    "\n",
    "print(f\"Siap untuk men-scrape {len(JOBS_TO_SCRAPE)} jenis pekerjaan.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b56836",
   "metadata": {},
   "source": [
    "### Proses Scraping Utama\n",
    "\n",
    "Loop di bawah ini akan memanggil fungsi `scrape_linkedin_jobs` untuk setiap pekerjaan yang telah kita definisikan di atas. Hasil dari setiap scrape akan disimpan dalam sebuah list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "763d1a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Memulai scraping untuk kategori: 'Data Analysis' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 28 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 28/28...\n",
      "--- Scraping untuk 'Data Analysis' selesai. Ditemukan 28 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Machine Learning' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 28 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 28/28...\n",
      "--- Scraping untuk 'Machine Learning' selesai. Ditemukan 28 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Software Tester' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 81 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 81/81...\n",
      "--- Scraping untuk 'Software Tester' selesai. Ditemukan 81 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Fullstack Developer' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 28 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 28/28...\n",
      "--- Scraping untuk 'Fullstack Developer' selesai. Ditemukan 28 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'UI/UX' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 28 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 28/28...\n",
      "--- Scraping untuk 'UI/UX' selesai. Ditemukan 28 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Cybersecurity' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 28 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 28/28...\n",
      "--- Scraping untuk 'Cybersecurity' selesai. Ditemukan 28 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Quality Assurance' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 28 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 28/28...\n",
      "--- Scraping untuk 'Quality Assurance' selesai. Ditemukan 28 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'DevOps' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 81 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 81/81...\n",
      "--- Scraping untuk 'DevOps' selesai. Ditemukan 81 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Writer' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 81 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 81/81...\n",
      "--- Scraping untuk 'Writer' selesai. Ditemukan 81 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Editor' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 28 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 28/28...\n",
      "--- Scraping untuk 'Editor' selesai. Ditemukan 28 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Akuntan (ID)' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 27 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 27/27...\n",
      "--- Scraping untuk 'Akuntan (ID)' selesai. Ditemukan 27 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Accountant (EN)' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 24 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 24/24...\n",
      "--- Scraping untuk 'Accountant (EN)' selesai. Ditemukan 24 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Staf Akuntansi (ID)' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 16 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 16/16...\n",
      "--- Scraping untuk 'Staf Akuntansi (ID)' selesai. Ditemukan 16 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Accounting Staff (EN)' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 80 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 80/80...\n",
      "--- Scraping untuk 'Accounting Staff (EN)' selesai. Ditemukan 80 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Manajer Keuangan (ID)' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 28 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 28/28...\n",
      "--- Scraping untuk 'Manajer Keuangan (ID)' selesai. Ditemukan 28 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Finance Manager (EN)' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 28 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 28/28...\n",
      "--- Scraping untuk 'Finance Manager (EN)' selesai. Ditemukan 28 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Analis Keuangan (ID)' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 4 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 4/4...\n",
      "--- Scraping untuk 'Analis Keuangan (ID)' selesai. Ditemukan 4 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Financial Analyst (EN)' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 28 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 28/28...\n",
      "--- Scraping untuk 'Financial Analyst (EN)' selesai. Ditemukan 28 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Auditor' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 28 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 28/28...\n",
      "--- Scraping untuk 'Auditor' selesai. Ditemukan 28 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Manajer Pemasaran (ID)' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 31 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 31/31...\n",
      "--- Scraping untuk 'Manajer Pemasaran (ID)' selesai. Ditemukan 31 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Marketing Manager (EN)' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 81 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 81/81...\n",
      "--- Scraping untuk 'Marketing Manager (EN)' selesai. Ditemukan 81 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Staf Pemasaran (ID)' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 24 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 24/24...\n",
      "--- Scraping untuk 'Staf Pemasaran (ID)' selesai. Ditemukan 24 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Marketing Staff (EN)' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 28 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 28/28...\n",
      "--- Scraping untuk 'Marketing Staff (EN)' selesai. Ditemukan 28 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Sales Executive' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 28 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 28/28...\n",
      "--- Scraping untuk 'Sales Executive' selesai. Ditemukan 28 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Social Media Specialist' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 81 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 81/81...\n",
      "--- Scraping untuk 'Social Media Specialist' selesai. Ditemukan 81 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Brand Manager' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 28 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 28/28...\n",
      "--- Scraping untuk 'Brand Manager' selesai. Ditemukan 28 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'HRD' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 28 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 28/28...\n",
      "--- Scraping untuk 'HRD' selesai. Ditemukan 28 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Human Resources (EN)' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 81 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 81/81...\n",
      "--- Scraping untuk 'Human Resources (EN)' selesai. Ditemukan 81 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Staf Rekrutmen (ID)' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 8 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 8/8...\n",
      "--- Scraping untuk 'Staf Rekrutmen (ID)' selesai. Ditemukan 8 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Recruiter (EN)' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 80 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 80/80...\n",
      "--- Scraping untuk 'Recruiter (EN)' selesai. Ditemukan 80 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Payroll' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 28 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 28/28...\n",
      "--- Scraping untuk 'Payroll' selesai. Ditemukan 28 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Talent Acquisition' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 28 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 28/28...\n",
      "--- Scraping untuk 'Talent Acquisition' selesai. Ditemukan 28 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Manajer Operasional (ID)' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 28 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 28/28...\n",
      "--- Scraping untuk 'Manajer Operasional (ID)' selesai. Ditemukan 28 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Operations Manager (EN)' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 28 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 28/28...\n",
      "--- Scraping untuk 'Operations Manager (EN)' selesai. Ditemukan 28 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Staf Logistik (ID)' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 24 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 24/24...\n",
      "--- Scraping untuk 'Staf Logistik (ID)' selesai. Ditemukan 24 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Logistics Staff (EN)' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 28 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 28/28...\n",
      "--- Scraping untuk 'Logistics Staff (EN)' selesai. Ditemukan 28 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Supply Chain' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 28 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 28/28...\n",
      "--- Scraping untuk 'Supply Chain' selesai. Ditemukan 28 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Staf Gudang (ID)' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 16 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 16/16...\n",
      "--- Scraping untuk 'Staf Gudang (ID)' selesai. Ditemukan 16 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Warehouse Staff (EN)' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 28 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 28/28...\n",
      "--- Scraping untuk 'Warehouse Staff (EN)' selesai. Ditemukan 28 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Guru' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 81 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 81/81...\n",
      "--- Scraping untuk 'Guru' selesai. Ditemukan 81 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Dosen (ID)' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 50 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 50/50...\n",
      "--- Scraping untuk 'Dosen (ID)' selesai. Ditemukan 50 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Lecturer (EN)' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 28 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 28/28...\n",
      "--- Scraping untuk 'Lecturer (EN)' selesai. Ditemukan 28 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Konselor Pendidikan (ID)' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 0 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "\n",
      "--- Scraping untuk 'Konselor Pendidikan (ID)' selesai. Ditemukan 0 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Education Counselor (EN)' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 35 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 35/35...\n",
      "--- Scraping untuk 'Education Counselor (EN)' selesai. Ditemukan 35 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Perawat' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 55 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 55/55...\n",
      "--- Scraping untuk 'Perawat' selesai. Ditemukan 55 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Analis Kesehatan (ID)' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 24 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 24/24...\n",
      "--- Scraping untuk 'Analis Kesehatan (ID)' selesai. Ditemukan 24 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Health Analyst (EN)' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 12 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 12/12...\n",
      "--- Scraping untuk 'Health Analyst (EN)' selesai. Ditemukan 12 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Apoteker (ID)' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 64 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 64/64...\n",
      "--- Scraping untuk 'Apoteker (ID)' selesai. Ditemukan 64 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Pharmacist (EN)' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 60 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 60/60...\n",
      "--- Scraping untuk 'Pharmacist (EN)' selesai. Ditemukan 60 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Staf Legal (ID)' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 20 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 20/20...\n",
      "--- Scraping untuk 'Staf Legal (ID)' selesai. Ditemukan 20 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Legal Staff (EN)' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 81 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 81/81...\n",
      "--- Scraping untuk 'Legal Staff (EN)' selesai. Ditemukan 81 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Pengacara (ID)' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 0 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "\n",
      "--- Scraping untuk 'Pengacara (ID)' selesai. Ditemukan 0 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Lawyer (EN)' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 57 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 57/57...\n",
      "--- Scraping untuk 'Lawyer (EN)' selesai. Ditemukan 57 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Corporate Lawyer' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 28 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 28/28...\n",
      "--- Scraping untuk 'Corporate Lawyer' selesai. Ditemukan 28 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Manajer Hotel (ID)' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 4 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 4/4...\n",
      "--- Scraping untuk 'Manajer Hotel (ID)' selesai. Ditemukan 4 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Hotel Manager (EN)' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 28 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 28/28...\n",
      "--- Scraping untuk 'Hotel Manager (EN)' selesai. Ditemukan 28 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Chef' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 28 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 28/28...\n",
      "--- Scraping untuk 'Chef' selesai. Ditemukan 28 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'F&B Service' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 28 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 28/28...\n",
      "--- Scraping untuk 'F&B Service' selesai. Ditemukan 28 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "--- Memulai scraping untuk kategori: 'Front Office' ---\n",
      "  Mengambil link dari halaman 1/4...\n",
      "  Mengambil link dari halaman 2/4...\n",
      "  Mengambil link dari halaman 3/4...\n",
      "  Mengambil link dari halaman 4/4...\n",
      "Total 81 link pekerjaan unik ditemukan. Memulai scraping detail...\n",
      "  -> Mengambil detail dari link 81/81...\n",
      "--- Scraping untuk 'Front Office' selesai. Ditemukan 81 pekerjaan. ---\n",
      "\n",
      "Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\n",
      "\n",
      "\n",
      "===== SEMUA KATEGORI TELAH SELESAI DI-SCRAPE! =====\n"
     ]
    }
   ],
   "source": [
    "all_scraped_dfs = []\n",
    "\n",
    "# Loop melalui setiap item di dictionary pekerjaan\n",
    "for job_name, keyword in JOBS_TO_SCRAPE.items():\n",
    "    # Buat URL lengkap\n",
    "    full_url = BASE_URL + keyword\n",
    "    \n",
    "    # Panggil fungsi scraping\n",
    "    df_result = scrape_linkedin_jobs(full_url, job_name, max_pages=4) # Ambil 4 halaman (100 jobs) per kategori\n",
    "    \n",
    "    if not df_result.empty:\n",
    "        all_scraped_dfs.append(df_result)\n",
    "        \n",
    "    print(\"Memberi jeda 10 detik sebelum lanjut ke kategori berikutnya...\")\n",
    "    time.sleep(10)\n",
    "\n",
    "print(\"\\n\\n===== SEMUA KATEGORI TELAH SELESAI DI-SCRAPE! =====\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed09a0fa",
   "metadata": {},
   "source": [
    "#### Menggabungkan, Membersihkan, dan Menyimpan Data\n",
    "\n",
    "Setelah semua data terkumpul, sel ini akan menggabungkannya menjadi satu DataFrame besar, menghapus data yang duplikat, dan menyimpannya ke dalam satu file CSV akhir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e16d7eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data baru yang berhasil di-scrape: 2200 baris.\n",
      "Berhasil memuat 5251 data pekerjaan lama dari './dataset/jobs_dataset.csv'\n",
      "\n",
      "Total data gabungan (lama + baru) sebelum pembersihan duplikat: 7451 baris.\n",
      "Total data unik setelah pembersihan duplikat final: 7451 baris.\n",
      "\n",
      "Contoh 5 baris pertama dari dataset gabungan final:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Company",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Location",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Country",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Job Description",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Job Requirements",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Link",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Work Type",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "bb5a717d-f7a2-48fc-99be-9333aad89293",
       "rows": [
        [
         "0",
         "Data Analyst, Business Intelligence",
         "Shopee",
         "Jakarta, Indonesia",
         " Indonesia",
         "Assist the various business units as a discussion partner to plan, strategise, and grow Shopee's business by enabling data-driven decision-making | Collect, clean, and analyze large data sets to support business decisions | Develop and deploy dashboards to monitor key metrics.",
         "Serve as in-consultant who simplifies complex terminologies into more understandable insights to internal stakeholders | Conduct ad-hoc analysis to support decision-making and special projects | Master's or Bachelor's degree in quantitative fields or a relevant field of study | Experience working with one or more language for querying (e.g. SQL) | Familiarity working with BI tools (e.g Tableau, PowerBI, Looker) strongly preferred | Familiarity with advanced analytics languages like Python or R will be an advantage | Experience working with multiple stakeholders across various divisions | Ability to converse in English and Bahasa Indonesia to communicate with internal stakeholders | Exceptional interpersonal skills | Self-starter with a can-do attitude",
         "https://id.linkedin.com/jobs/view/data-analyst-business-intelligence-at-shopee-3611204797?position=1&pageNum=0&refId=YMwWFleeYCES%2FUzpgqppow%3D%3D&trackingId=dfumxOdWdYGvfprHv%2BgTMA%3D%3D",
         null
        ],
        [
         "1",
         "Business Analyst - SPX Express (Jakarta)",
         "Shopee",
         "Jakarta, Indonesia",
         " Indonesia",
         "Not Found",
         "Perform deep data analysis to find pattern of lost & damaged parcels | Use advanced query to play around with logistics data to detect fraud and operational inefficiencies. | Conduct root cause analysis and recommend process improvements to close loopholes. | Collaborate with cross-functional and strategic teams to present data insights. | Stay updated on industry trends and best practices in fraud detection. | 2+ years of experience in data analysis, risk or consulting roles, and preferably within logistics, supply chain, or fraud detection industries. | Proficiency in SQL and Excel data modeling for analysis. | Additional advantage if you're experienced with Python or R for data analysis and modeling. | Demonstrated ability to work with strategic teams and present data insights effectively. | Strong problem-solving skills and logical thinking capabilities.",
         "https://id.linkedin.com/jobs/view/business-analyst-spx-express-jakarta-at-shopee-4211853597?position=2&pageNum=0&refId=YMwWFleeYCES%2FUzpgqppow%3D%3D&trackingId=E2A%2FgdCzVfnXIu3RcUEU8A%3D%3D",
         null
        ],
        [
         "2",
         "Data Analyst Marketing",
         "PT ASTRA OTOPARTS Tbk",
         "Jakarta, Jakarta, Indonesia",
         " Indonesia",
         "Not Found",
         "Analysis about domestic performance, survey, research and big data. | Bachelor Degree (S1) from any reputable university with GPA min. 3.00 | Fresh graduate or 2 years working experiences | Passionate on research and number",
         "https://id.linkedin.com/jobs/view/data-analyst-marketing-at-pt-astra-otoparts-tbk-4014381150?position=3&pageNum=0&refId=YMwWFleeYCES%2FUzpgqppow%3D%3D&trackingId=yLQIC5ytYalaUyDUAoBh8g%3D%3D",
         null
        ],
        [
         "3",
         "Business Analyst",
         "OTO",
         "Jakarta, Indonesia",
         " Indonesia",
         "Not Found",
         "Collecting, analyzing and interpreting data, and creating reports that can be used to inform the overall business strategy. | You will work with various teams to identify trends, patterns, and opportunities, and provide insights on key metrics. | Communicating findings to stakeholders and aligning data-driven strategy. | Bachelor's Degree in Engineering, Finance, Economics, or related field is required | Having experience working in a consulting firm or a similar field is a plus | Prior experience working as a Business Analyst / Consultant or related role (1-4years) | Proficient in MS Excel, SQL and Data Visualization Tools such as Tableau and Python | Strong analytical and problem-solving skills | Excellent written and verbal communication skills (English & Bahasa) | Ability to work independently and in a team environment | Experience in the automotive industry is a plus | Knowledge of statistical analysis, data mining, and machine learning is a plus",
         "https://id.linkedin.com/jobs/view/business-analyst-at-oto-4228739548?position=4&pageNum=0&refId=YMwWFleeYCES%2FUzpgqppow%3D%3D&trackingId=66GkIejAf0eStEW6qSn8lw%3D%3D",
         null
        ],
        [
         "4",
         "Wholesale Risk Analyst",
         "PT. Bank Tabungan Negara (Persero) Tbk",
         "Jakarta, Indonesia",
         " Indonesia",
         "Not Found",
         "Not Found",
         "https://id.linkedin.com/jobs/view/wholesale-risk-analyst-at-pt-bank-tabungan-negara-persero-tbk-4230431620?position=5&pageNum=0&refId=YMwWFleeYCES%2FUzpgqppow%3D%3D&trackingId=CrpFUhSyGE4AjieFVqzGEQ%3D%3D",
         null
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Country</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Job Requirements</th>\n",
       "      <th>Link</th>\n",
       "      <th>Work Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst, Business Intelligence</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Assist the various business units as a discuss...</td>\n",
       "      <td>Serve as in-consultant who simplifies complex ...</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/data-analyst...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Business Analyst - SPX Express (Jakarta)</td>\n",
       "      <td>Shopee</td>\n",
       "      <td>Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Perform deep data analysis to find pattern of ...</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/business-ana...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst Marketing</td>\n",
       "      <td>PT ASTRA OTOPARTS Tbk</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Analysis about domestic performance, survey, r...</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/data-analyst...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>OTO</td>\n",
       "      <td>Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Collecting, analyzing and interpreting data, a...</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/business-ana...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wholesale Risk Analyst</td>\n",
       "      <td>PT. Bank Tabungan Negara (Persero) Tbk</td>\n",
       "      <td>Jakarta, Indonesia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>https://id.linkedin.com/jobs/view/wholesale-ri...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Title  \\\n",
       "0       Data Analyst, Business Intelligence   \n",
       "1  Business Analyst - SPX Express (Jakarta)   \n",
       "2                    Data Analyst Marketing   \n",
       "3                          Business Analyst   \n",
       "4                    Wholesale Risk Analyst   \n",
       "\n",
       "                                  Company                     Location  \\\n",
       "0                                  Shopee           Jakarta, Indonesia   \n",
       "1                                  Shopee           Jakarta, Indonesia   \n",
       "2                   PT ASTRA OTOPARTS Tbk  Jakarta, Jakarta, Indonesia   \n",
       "3                                     OTO           Jakarta, Indonesia   \n",
       "4  PT. Bank Tabungan Negara (Persero) Tbk           Jakarta, Indonesia   \n",
       "\n",
       "      Country                                    Job Description  \\\n",
       "0   Indonesia  Assist the various business units as a discuss...   \n",
       "1   Indonesia                                          Not Found   \n",
       "2   Indonesia                                          Not Found   \n",
       "3   Indonesia                                          Not Found   \n",
       "4   Indonesia                                          Not Found   \n",
       "\n",
       "                                    Job Requirements  \\\n",
       "0  Serve as in-consultant who simplifies complex ...   \n",
       "1  Perform deep data analysis to find pattern of ...   \n",
       "2  Analysis about domestic performance, survey, r...   \n",
       "3  Collecting, analyzing and interpreting data, a...   \n",
       "4                                          Not Found   \n",
       "\n",
       "                                                Link Work Type  \n",
       "0  https://id.linkedin.com/jobs/view/data-analyst...       NaN  \n",
       "1  https://id.linkedin.com/jobs/view/business-ana...       NaN  \n",
       "2  https://id.linkedin.com/jobs/view/data-analyst...       NaN  \n",
       "3  https://id.linkedin.com/jobs/view/business-ana...       NaN  \n",
       "4  https://id.linkedin.com/jobs/view/wholesale-ri...       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "PROSES SELESAI!\n",
      "Dataset gabungan (IT dan Non-IT) berhasil disimpan ke file './dataset/jobs_dataset_LENGKAP.csv'\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "if all_scraped_dfs:\n",
    "    # --- LANGKAH 1: Gabungkan semua DataFrame yang BARU di-scrape ---\n",
    "    newly_scraped_df = pd.concat(all_scraped_dfs, ignore_index=True)\n",
    "    print(f\"Total data baru yang berhasil di-scrape: {len(newly_scraped_df)} baris.\")\n",
    "\n",
    "    # --- LANGKAH 2: Muat DataFrame LAMA yang sudah ada ---\n",
    "    existing_dataset_path = \"./dataset/jobs_dataset.csv\" \n",
    "    try:\n",
    "        df_existing = pd.read_csv(existing_dataset_path)\n",
    "        print(f\"Berhasil memuat {len(df_existing)} data pekerjaan lama dari '{existing_dataset_path}'\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Peringatan: File lama '{existing_dataset_path}' tidak ditemukan. Hanya data baru yang akan disimpan.\")\n",
    "        df_existing = pd.DataFrame() # Buat DataFrame kosong jika file tidak ada\n",
    "\n",
    "    # --- LANGKAH 3: Gabungkan data LAMA dan data BARU ---\n",
    "    final_combined_df = pd.concat([df_existing, newly_scraped_df], ignore_index=True)\n",
    "    print(f\"\\nTotal data gabungan (lama + baru) sebelum pembersihan duplikat: {len(final_combined_df)} baris.\")\n",
    "\n",
    "    # --- LANGKAH 4: Lakukan pembersihan duplikat FINAL pada data gabungan ---\n",
    "    # menghilangkan data yang mungkin ter-scrape ulang atau sudah ada sebelumnya\n",
    "    final_combined_df.drop_duplicates(subset=[\"Title\", \"Company\", \"Location\", \"Link\"], inplace=True, keep='last')\n",
    "    print(f\"Total data unik setelah pembersihan duplikat final: {len(final_combined_df)} baris.\")\n",
    "\n",
    "    # Tampilkan contoh hasil akhir\n",
    "    print(\"\\nContoh 5 baris pertama dari dataset gabungan final:\")\n",
    "    display(final_combined_df.head())\n",
    "\n",
    "    # --- LANGKAH 5: Simpan ke file CSV gabungan yang baru ---\n",
    "    output_filename = \"./dataset/jobs_dataset_LENGKAP.csv\"\n",
    "    final_combined_df.to_csv(output_filename, index=False)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"PROSES SELESAI!\")\n",
    "    print(f\"Dataset gabungan (IT dan Non-IT) berhasil disimpan ke file '{output_filename}'\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "else:\n",
    "    print(\"Tidak ada data baru yang berhasil di-scrape. Proses dihentikan.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "dsml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3974.471917,
   "end_time": "2025-05-22T08:19:14.428311",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-22T07:12:59.956394",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
